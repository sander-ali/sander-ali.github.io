<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Daily AI news | Sunder Ali Khowaja </title> <meta name="author" content="Sunder Ali Khowaja"> <meta name="description" content="This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI"> <meta name="keywords" content="Khowaja Sunder, Sunder Ali Khowaja, Sander Ali Khowaja, dr.Sunder Ali Khowaja, doctor sunder khowaja, sunder ali, sander ali, dr sunder ali contact number, IEEE Senior Member, sunder ali usindh, sander ali usindh, deep-learning, computer-vision, AI-researcher, machine-learning, model inversion attacks, medical-imaging, private ai, neural-networks, academic-publications, research-portfolio"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img//favicon.png?5db4cf704bc2caffc10b1d53e8fa8ffd"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sander-ali.github.io/projects/Daily_AI_News/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Sunder Ali Khowaja </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blogs </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/updates/">News </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Daily AI news</h1> <p class="post-description">This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI</p> </header> <article> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/logo_SAK_15.PNG" target="_blank"> <img src="/assets/img/news/logo_SAK_15.PNG" alt="Comapny Logo"> </a> </div> </div> <h1> 25th March 2025 </h1> <h1> ğŸ¦¾ JUST IN: Unitree's G1 Robot Nails First-Ever Standing Side Flip </h1> <p>Humanoid robotics just reached a milestone that seemed impossible just months ago.</p> <p>â†˜ï¸Comes just one year after Unitreeâ€™s H1 (1.8m) pioneered the first standing backflip by an electric humanoid.</p> <p>â†˜ï¸Demonstrates flawless execution of a more technically challenging maneuver than the backflip.</p> <p>â†˜ï¸Zero hardware malfunctions or damage occurred throughout programming and filming.</p> <p>The precision control systems that enable these flips are the same technologies that will allow humanoids to navigate complex real-world environments, respond to unexpected obstacles, and perform intricate tasks alongside humans.</p> <p>What everyday applications do you see for humanoid robots with this level of physical dexterity and dynamic control?</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;"> <iframe width="560" height="315" src="https://www.youtube.com/embed/29xLWhqME2Q?si=jd4rBvX4774GRODg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> </div> </div> <hr> <hr> <h1> ğŸ™ï¸ Oliva: Voice RAG Assistant </h1> <p>A powerful open-source assistant that enables natural voice search of vector databases. Built with LangChainâ€™s workflow engine and cutting-edge voice tech, Oliva delivers seamless agentic RAG capabilities.</p> <p>Check it out ğŸš€ https://github.com/Deluxer/oliva</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/2.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/2.jpg" alt="Nyx"> </a> </div> </div> <hr> <hr> <h1> LlamaExtract is now in public beta ğŸ”¥ </h1> <p>The leading, genAI-native agent for structured document extraction.</p> <p>We adapt the latest models and tune them so that you can structure even the most complex documents (financial reports, invoices, resumes, and more) in a highly accurate, reliable way.</p> <p>No more worrying about</p> <p>1) overflowing the context window,</p> <p>2) getting misformatted json,</p> <p>3) figuring out how to version your agent.</p> <p>Itâ€™s built on the same foundation as LlamaParse, our parsing service, which allows understanding of even the most complex documents.</p> <p>Big shoutout to Neeraj Pradhan for driving this forward.</p> <p>Check it out: https://cloud.llamaindex.ai/login Sample Notebook: https://github.com/run-llama/llama_cloud_services/blob/main/examples/extract/resume_screening.ipynb</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/3.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/3.jpg" alt="Nyx"> </a> </div> </div> <hr> <hr> <h1> Forget RAG, welcome Agentic RAG </h1> <p>ğ—¡ğ—®ğ˜ğ—¶ğ˜ƒğ—² ğ—¥ğ—”ğ—š</p> <p>In Native RAG, the most common implementation nowadays, the user query is processed through a pipeline that includes retrieval, reranking, synthesis, and generation of a response.</p> <p>This process leverages retrieval and generation-based methods to provide accurate and contextually relevant answers.</p> <p>ğ—”ğ—´ğ—²ğ—»ğ˜ğ—¶ğ—° ğ—¥ğ—”ğ—š</p> <p>Agentic RAG is an advanced, agent-based approach to question answering over multiple documents in a coordinated manner. It involves comparing different documents, summarizing specific documents, or comparing various summaries.</p> <p>Agentic RAG is a flexible framework that supports complex tasks requiring planning, multi-step reasoning, tool use, and learning over time.</p> <p>ğ—ğ—²ğ˜† ğ—–ğ—¼ğ—ºğ—½ğ—¼ğ—»ğ—²ğ—»ğ˜ğ˜€ ğ—®ğ—»ğ—± ğ—”ğ—¿ğ—°ğ—µğ—¶ğ˜ğ—²ğ—°ğ˜ğ˜‚ğ—¿ğ—²</p> <ul> <li> <p>Document Agents: Each document is assigned a dedicated agent capable of answering questions and summarizing within its own document.</p> </li> <li> <p>Meta-Agent: A top-level agent manages all the document agents, orchestrating their interactions and integrating their outputs to generate a coherent and comprehensive response.</p> </li> </ul> <p>ğ—™ğ—²ğ—®ğ˜ğ˜‚ğ—¿ğ—²ğ˜€ ğ—®ğ—»ğ—± ğ—•ğ—²ğ—»ğ—²ğ—³ğ—¶ğ˜ğ˜€</p> <ul> <li> <p>Autonomy: Agents act independently to retrieve, process, and generate information.</p> </li> <li> <p>Adaptability: The system can adjust strategies based on new data and changing contexts.</p> </li> <li> <p>Proactivity: Agents can anticipate needs and take preemptive actions to achieve goals. Applications</p> </li> </ul> <p>Agentic RAG is particularly useful in scenarios requiring thorough and nuanced information processing and decision-making.</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/4.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/4.jpg" alt="Nyx"> </a> </div> </div> <hr> <hr> <h1> ğŸ¤–BREAKING: NVIDIA Drops First-Ever Open Foundation Model for Humanoid Robots </h1> <p>The race to develop general-purpose humanoid robots just accelerated dramatically!</p> <p>Key information:</p> <p>ğŸ”¸GR00T N1 features a dual-system cognitive architecture with a Vision-Language Model for reasoning and a Diffusion Transformer for generating precise movements</p> <p>ğŸ”¸The model achieves 76.8% success rate on real-world tasks - dramatically outperforming baseline methods, especially with limited training data</p> <p>ğŸ”¸NVIDIAâ€™s synthetic data strategy generated 750K trajectories in just 11 hours (equivalent to 9 months of human demonstrations)</p> <p>ğŸ”¸The 2B parameter model is now available on Hugging Face with sample datasets and PyTorch scripts for customization</p> <p>How do you think general-purpose humanoid robots will transform manufacturing and logistics in the coming years?</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <iframe width="560" height="315" src="https://www.youtube.com/embed/BslFNYJjjb4?si=6Z2UtdVkBAG8ODnj" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> </div> </div> <hr> <hr> <h1> Improving small model abilities with DeepSeek AI R1 few shots. </h1> <p>A new experiment powered by Hugging Face Inference Providers and Data Studio!</p> <p>Last week, I shared the LIMO (Less is more for reasoning) dataset categorized with Llama 70B. I aimed to understand the topic distribution of this small but powerful dataset.</p> <p>This time, I wanted to experiment with a new idea: what if we could use few-shot examples (demonstrations) from R1 to improve Llamaâ€™s ability to extract topics?</p> <p>Hereâ€™s what I did:</p> <ol> <li> <p>Run R1 over a few rows.</p> </li> <li> <p>Inspect and validate the results.</p> </li> <li> <p>Use 5 validated R1 responses as part of the prompt to Llama.</p> </li> <li> <p>Categorize the entire dataset.</p> </li> <li> <p>Use Data Studio to extract the distribution of topics and compare it to my previous dataset.</p> </li> </ol> <p>It all took under 30 minutes. Itâ€™s amazing how quickly you can turn ideas into results using the Hub!</p> <p>Dataset:</p> <p>https://huggingface.co/datasets/dvilasuero/LIMO-topics-r1-fewshots</p> <p>Topics with Llama 70B:</p> <p>https://huggingface.co/datasets/dvilasuero/GAIR_LIMO_topics/sql-console/eNIH1nJ</p> <p>Topics with Llama + R1 few shots:</p> <p>https://huggingface.co/datasets/dvilasuero/LIMO-topics-r1-fewshots/sql-console/rDsKKX9</p> <p>Prompt for R1 (needed to add explicit instruction not to solve the problem ğŸ¤£ )</p> <p>Classify the math topics of the question. You MUST NO SOLVE the question, just analyze and give me a list of very precise topics that are needed to solve the question:</p> <p>Pipeline:</p> <p>https://huggingface.co/datasets/dvilasuero/LIMO-topics-r1-fewshots/blob/main/config.yml</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/5.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/5.jpg" alt="Nyx"> </a> </div> </div> <hr> <hr> <h1> Qwen just DROPPED a 32B VLM - beats Qwen 2.5 72B and GPT 4o Mini - Apache 2.0 licensed ğŸ”¥ </h1> <p>Vision Tasks (vs. Qwen2-VL-72B):</p> <blockquote> <p>MMMU: 70.0 (vs. 64.5)</p> </blockquote> <blockquote> <p>MathVista: 74.7 (vs. 70.5)</p> </blockquote> <blockquote> <p>OCRBenchV2: 57.2/59.1 (vs. 47.8/46.1)</p> </blockquote> <blockquote> <p>Android Control: 69.6/93.3 (vs. 66.4/84.4)</p> </blockquote> <p>Text Tasks (vs. Competing Models):</p> <blockquote> <p>MMLU: 78.4 (vs. Mistral-24B: 80.6, GPT-4o-Mini: 82.0)</p> </blockquote> <blockquote> <p>MATH: 82.2 (vs. Gemma3-27B: 89.0, GPT-4o-Mini: 70.2)</p> </blockquote> <blockquote> <p>HumanEval: 91.5 (vs. Claude-3.5-Haiku: 88.1)</p> </blockquote> <p>Multimodal Capabilities:</p> <blockquote> <p>Recognizes objects, analyzes text/charts/graphics, and supports structured outputs (e.g., invoices, tables)</p> </blockquote> <blockquote> <p>Acts as a visual agent, dynamically using tools for computer/phone interactions</p> </blockquote> <blockquote> <p>Understands 1+ hour videos and pinpoints relevant segments (temporal localization)</p> </blockquote> <blockquote> <p>Generates bounding boxes/points with stable JSON outputs</p> </blockquote> <p>Very cool to see Qwen ship such a competitive multimodal model! ğŸ¤—</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/7.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/7.jpg" alt="Nyx"> </a> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0 text-left"> Â© Copyright 2025 Sunder Ali Khowaja. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-82147914-4"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-82147914-4");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>for(var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.querySelectorAll('[id="WeChatBtn"]'),i=0;i<wechatBtn.length;i++)wechatBtn[i].onclick=function(){wechatModal.style.display="block"};window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-cv",title:"CV",description:"Below is a simplified version of my resume. You can find a full version in the pdf. \ud83d\udc49",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-publications",title:"Publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-blogs",title:"Blogs",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-teaching",title:"Teaching",description:"Courses and teaching activities at various institutions",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"nav-news",title:"News",description:"",section:"Navigation",handler:()=>{window.location.href="/updates/"}},{id:"post-what-is-the-technical-debt-of-large-language-models-llms-and-how-does-it-affect-us",title:"What Is the Technical Debt of Large Language Models (LLMs) and How Does...",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/What-Is-the-Technical-Debt-of-Large-Language-Models-(LLMs)-and-How-Does-It-Affect-Us/"}},{id:"post-open-source-ai-taking-forward-leaps",title:"Open Source AI taking forward leaps",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/Open-Source-AI-taking-forward-leaps/"}},{id:"post-summarizing-youtube-videos-using-python-and-online-ai-tools",title:"Summarizing YouTube Videos using Python and Online AI Tools",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/Summarizing-YouTube-Videos-using-Python-and-Online-AI-Tools/"}},{id:"post-taking-a-deep-dive-into-yolov8",title:"Taking a Deep Dive into YOLOv8",description:"Details on YOLOv8",section:"Posts",handler:()=>{window.location.href="/blog/2023/Taking-a-Deep-Dive-into-YOLOv8/"}},{id:"post-brief-timeline-of-yolo-models",title:"Brief Timeline of YOLO models",description:"Brief Timeline of YOLO models from v1 to v8",section:"Posts",handler:()=>{window.location.href="/blog/2023/Brief-Timeline-of-YOLO-models-from-v1-to-v8/"}},{id:"post-combating-urban-flooding-with-internet-of-things-and-artificial-intelligence",title:"Combating Urban flooding with Internet of Things and Artificial Intelligence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/Combating-Urban-flooding-with-Internet-of-Things-and-Artificial-Intelligence/"}},{id:"post-where-do-pakistan-stand-in-ai-race",title:"Where do Pakistan stand in AI race?",description:"A discussion on where Pakistan resides in terms of AI race.",section:"Posts",handler:()=>{window.location.href="/blog/2020/Where-do-Pakistan-stand-in-AI-race/"}},{id:"projects-best-paper-award-at-kdbc-2018",title:"Best Paper Award at KDBC 2018",description:"Our paper titled Human Action Recognition with Sequential Convolution and Recurrent Neural Networks Using 3D Skeleton Data, has won the best paper award in Korean Database Conference held at South Korea.",section:"Projects",handler:()=>{window.location.href="/projects/Best_Paper_Award_KDBC/"}},{id:"projects-first-runner-up-at-cvpr-2023-6th-ug2-challenge",title:"First Runner Up at CVPR 2023 6th UG2+ Challenge",description:"First Runner Up at CVPR 2023 6th UG2+ Challenge",section:"Projects",handler:()=>{window.location.href="/projects/UG2_FRU_Cert/"}},{id:"projects-second-runner-up-at-cvpr-2023-6th-ug2-challenge",title:"Second Runner Up at CVPR 2023 6th UG2+ Challenge",description:"Second Runner Up at CVPR 2023 6th UG2+ Challenge",section:"Projects",handler:()=>{window.location.href="/projects/UG2_SRU_Cert/"}},{id:"projects-ieee-tmi-distinguished-reviewer-bronze-level-2022-to-2023",title:"IEEE TMI Distinguished Reviewer Bronze Level 2022 to 2023",description:"IEEE TMI Distinguished Reviewer Bronze Level 2022 to 2023",section:"Projects",handler:()=>{window.location.href="/projects/TMI_reviewer/"}},{id:"projects-joined-as-ieee-consumer-technology-society-39-s-technical-committee-member",title:"Joined as IEEE Consumer Technology Society&#39;s Technical Committee Member",description:"Joined as IEEE Consumer Technology Society&#39;s Technical Committee Member",section:"Projects",handler:()=>{window.location.href="/projects/CTSoc_technical_member/"}},{id:"projects-best-paper-award-at-ieee-wcnc-2024",title:"Best Paper Award at IEEE WCNC 2024",description:"Our paper titled Zero-Trust Attack Framework with Split Learning for Autonomous Vehicles in 6G Networks, has won the best paper award at 25th IEEE Wireless Communications and Networking Conference held at Dubai, UAE",section:"Projects",handler:()=>{window.location.href="/projects/Best_Paper_Award_WCNC/"}},{id:"projects-serving-as-special-session-chair-at-ieee-gem-2024",title:"Serving as Special Session Chair at IEEE GEM 2024",description:"Call for papers in Special Session at IEEE Gaming, Entertainment and Media (GEM) conference, 2024",section:"Projects",handler:()=>{window.location.href="/projects/Chair_special_session_GEM/"}},{id:"projects-top-10-methods-at-cvpr-39-s-ntire-blind-compressed-image-enhancement-challenge",title:"Top 10 Methods at CVPR&#39;s NTIRE Blind Compressed Image Enhancement Challenge",description:"Our submission has been included in the top methods for NTIRE 2024 Blind Compressed Image Enhancement Challenge held at CVPR competitions.",section:"Projects",handler:()=>{window.location.href="/projects/NTIRE_BICE_Challenge/"}},{id:"projects-best-researcher-nomination-certificate",title:"Best Researcher Nomination Certificate",description:"Nomination Certificate for Early Career Researcher Award at Technological University (TU) Dublin, Ireland.",section:"Projects",handler:()=>{window.location.href="/projects/Best_researcher_nomination/"}},{id:"projects-daily-ai-news",title:"Daily AI news",description:"This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI",section:"Projects",handler:()=>{window.location.href="/projects/Daily_AI_News/"}},{id:"teaching-machine-learning",title:"Machine Learning",description:"2024_Machine_Learning.",section:"Teaching",handler:()=>{window.location.href="/teaching/Machine-Learning/"}},{id:"teaching-object-oriented-programming-java",title:"Object Oriented Programming (Java)",description:"2024_Object_oriented_programming_java.",section:"Teaching",handler:()=>{window.location.href="/teaching/object-oriented-programming-java/"}},{id:"teaching-object-oriented-programming-python",title:"Object Oriented Programming (Python)",description:"2024_Object_oriented_programming_python.",section:"Teaching",handler:()=>{window.location.href="/teaching/object-oriented-programming-python/"}},{id:"teaching-systems-and-network-database-administration",title:"Systems and Network Database Administration",description:"2024_Systems_Database_Administration.",section:"Teaching",handler:()=>{window.location.href="/teaching/systems-database-administration/"}},{id:"teaching-python-for-data-management",title:"Python for Data Management",description:"2024_python_for_data_management.",section:"Teaching",handler:()=>{window.location.href="/teaching/python-for-data-management/"}},{id:"teaching-program-design",title:"Program Design",description:"2024_Program_Design.",section:"Teaching",handler:()=>{window.location.href="/teaching/program-design/"}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}],console.log(ninja.data);</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>