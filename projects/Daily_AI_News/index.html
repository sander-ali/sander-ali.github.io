<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Daily AI news | Sunder Ali Khowaja </title> <meta name="author" content="Sunder Ali Khowaja"> <meta name="description" content="This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI"> <meta name="keywords" content="Khowaja Sunder, Sunder Ali Khowaja, Sander Ali Khowaja, dr.Sunder Ali Khowaja, doctor sunder khowaja, sunder ali, sander ali, dr sunder ali contact number, IEEE Senior Member, sunder ali usindh, sander ali usindh, deep-learning, computer-vision, AI-researcher, machine-learning, model inversion attacks, medical-imaging, private ai, neural-networks, academic-publications, research-portfolio"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img//favicon.png?5db4cf704bc2caffc10b1d53e8fa8ffd"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sander-ali.github.io/projects/Daily_AI_News/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Sunder Ali Khowaja </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blogs </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/updates/">News </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Daily AI news</h1> <p class="post-description">This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI</p> </header> <article> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/logo_SAK_15.PNG" target="_blank"> <img src="/assets/img/news/logo_SAK_15.PNG" alt="Comapny Logo"> </a> </div> </div> <h1> 5th March 2025 </h1> <h1> A2ZRadiology AI just released MC-MED </h1> <p>We just released MC-MED: 118,385 emergency department visits with continuous physiological waveforms. Nothing like this has existed before.</p> <p>Our Harvard/Stanford team built what AI Medicine researchers have needed for years‚Äîa dataset that captures both the clinical complexity and continuous physiological monitoring of emergency department care.</p> <p>What‚Äôs new here:</p> <ul> <li> <p>Continuous ECG, PPG and respiratory waveforms matched to clinical events</p> </li> <li> <p>Complete patient journeys from arrival to disposition</p> </li> <li> <p>Pandemic-era data (2020-2022) reflecting modern emergency care</p> </li> <li> <p>Scale that enables serious AI applications</p> </li> </ul> <p>This opens up research that was previously impossible‚Äîfrom early detection of deterioration to precision interventions based on physiological patterns.</p> <p>Built this with an incredible team: Aman Kansal, Emma (Ying) Chen, Tom Jin, and co-PI Prof. David Kim.</p> <p>Available now on PhysioNet: https://physionet.org/content/mc-med/1.0.0/</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/1.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/1.jpg" alt="Gemini"> </a> </div> </div> <h1> Turn any website into LLM-ready data in just a few lines of code! üî• </h1> <p>Introducing Firecrawl an open-source framework that takes a URL, crawls it, and converts it into a clean markdown or structured format.</p> <p>Key Features:</p> <p>‚Ä¢ üóÇÔ∏è Scrape: scrapes a URL and get its content in LLM-ready format (markdown, structured data via LLM Extract , screenshot, html)</p> <p>‚Ä¢ üìë Crawl: scrapes all the URLs of a web page and return content in LLM-ready format</p> <p>‚Ä¢ ‚Ü™Ô∏è Map: input a website and get all the website urls - extremely fast</p> <p>‚Ä¢ üîç Extract: get structured data from single page, multiple pages or entire websites with AI.</p> <p>The best part?</p> <p>It‚Äôs 100% Open Source</p> <p>Github Repo: https://github.com/mendableai/firecrawl</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/2.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/2.jpg" alt="OMi"> </a> </div> </div> <h1>Hugging Face launched LLM Reasoning Course</h1> <p>HuggingFace has just launched a new free course on ‚ÄúLLM Reasoning‚Äù for explaining how to build models like DeepSeek-R1. The course has a special focus towards Reinforcement Learning. The content looks great. Worth giving a try.</p> <p>Link : https://huggingface.co/reasoning-course</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/3.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/3.jpg" alt="Nyx"> </a> </div> </div> <h1> LFGG! Cohere just dropped Aya Vision 32B and 8B </h1> <p>LFGG! Cohere just dropped Aya Vision 32B and 8B - beats Llama 3.2 90B Vision and Gemini Flash üî•</p> <blockquote> <p>8B Model: Best-in-class for its parameter size, outperforming competitors by up to 81% win rates</p> </blockquote> <blockquote> <p>32B Model: Outperforms models 2x its size, achieving 49%-72% win rates</p> </blockquote> <p>Some notes on the release:</p> <blockquote> <p>Supports 23 languages and excelling in tasks like image captioning, visual question answering, and text generation</p> </blockquote> <blockquote> <p>Aya Vision 32B outperforms models more than twice its size (e.g., Llama-3.2 90B Vision, Molmo 72B) with win rates of 50%-64% on AyaVisionBench and 52%-72% on mWildVision</p> </blockquote> <blockquote> <p>8B achieves 79%-81% win rates against leading models in its parameter class (e.g., Qwen2.5-VL 7B, Gemini Flash 1.5 8B)</p> </blockquote> <blockquote> <p>Uses dynamic resizing and Pixel Shuffle to handle high-resolution images, reducing image tokens by 4x for improved latency and throughput</p> </blockquote> <blockquote> <p>Synthetic annotations and translation/rephrasing techniques enhance multilingual data coverage, improving win rates by 17.2% on AyaVisionBench</p> </blockquote> <blockquote> <p>Merging vision-language and base language models boosts generative capabilities, increasing win rates by 11.9% on AyaVisionBench</p> </blockquote> <p>Architecture:</p> <blockquote> <p>Vision Encoder: Initialized with SigLIP2-patch14-384 for high-resolution image processing</p> </blockquote> <blockquote> <p>Dynamic Resizing: Splits high-res images into tiles, processed with Pixel Shuffle for token compression</p> </blockquote> <blockquote> <p>Text Decoder: Initialized from Cohere Command R7B (8B) and Aya Expanse 32B (32B), fine-tuned with multilingual data</p> </blockquote> <blockquote> <p>Vision-Language Connector: Aligns image tokens with language model embeddings</p> </blockquote> <p>Training (Two-Stage Process):</p> <blockquote> <p>Vision-Language Alignment: Trains the connector while freezing the vision encoder and LLM</p> </blockquote> <blockquote> <p>SFT: Trains both connector and LLM on multilingual multimodal tasks</p> </blockquote> <blockquote> <p>Uses synthetic annotations, translation, and rephrasing to expand multilingual coverage</p> </blockquote> <blockquote> <p>Model Merging: Combines base LLM with fine-tuned vision-language model to enhance generative performance</p> </blockquote> <p>Model weights on Hugging Face and integrated on Transformers day-0 ü§ó</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/4.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/4.jpg" alt="ClaudeCode"> </a> </div> </div> <h1> Phi-4 beats SOTA Models </h1> <p>BOOM! Phi 4 Multimodal (MIT licensed) - the new king of the Open ASR Leaderboard üí•</p> <p>Beats Nvidia Canary, OpenAI Whisper and more ü§©</p> <p>Bonus: the model can do much more - speech summarisation, diarization and doubles up as an Audio LM too!</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/5.JPG" target="_blank"> <img src="/assets/img/news/AI%20news/5.JPG" alt="Gradio"> </a> </div> </div> <h1> GRPO can do more </h1> <p>Forget basic math problems. GRPO can do more! If you are exploring Reinforcement Learning you should take a look at the this blog post. üëÄ</p> <p>üí° Focuses on ambiguous text judgements (not just clear math answers).</p> <p>üìâ Constant learning rate (1e-6) + warmup beats decaying schedules.</p> <p>üìè Gradient clipping with max_grad_norm 0.2 keeps training stable (PPO‚Äôs secret sauce).</p> <p>üìù Used XML reward +0.2 reward for perfect formatting only if judgement is correct.</p> <p>‚ö° Explores power-scaling rewards (x‚Å¥) to scale down individual rewards for a overall bad batch.</p> <p>üìè Tested length based rewards for hitting ~128-tokens.</p> <p>üìà 7B model adapts 3x faster than 3B</p> <p>üîç High-reward samples reveal structured reasoning patterns, with phrases like ‚ÄúBoth of these‚Ä¶‚Äù and ‚ÄúHowever,‚Äù</p> <p>Read: https://kalomaze.bearblog.dev/grpo-judge-experiments-findings-and-empirical-observations/</p> <p>Based on: https://github.com/willccbb/verifiers</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/6.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/6.jpg" alt="BirdSQL"> </a> </div> </div> <h1> üöÄ Multimodal RAG with Docling and IBM's Granite 3.2! üöÄ </h1> <p>We‚Äôre thrilled to announce a comprehensive tutorial that guides you through building an AI-powered multimodal Retrieval-Augmented Generation (RAG) system using IBM‚Äôs latest Granite 3.2 model and Docling.</p> <p>Why This Matters:</p> <p>The Granite 3.2 model introduces enhanced reasoning capabilities, enabling more sophisticated understanding and generation of human-like text. When combined with Docling‚Äôs robust document parsing and conversion features, you can create AI systems that seamlessly process and comprehend diverse data types, including text and images, leading to more accurate and insightful responses.‚Äã</p> <p>Key Highlights:</p> <ol> <li> <p>Granite 3.2 Model: Experience the advanced reasoning and multimodal processing capabilities of IBM‚Äôs latest language model. ‚Äã</p> </li> <li> <p>Docling Integration: Efficiently handle and transform documents from various sources using this open-source toolkit. ‚Äã</p> </li> <li> <p>LangChain for Workflow Orchestration: Streamline and automate document processing and retrieval workflows, ensuring seamless interaction between different system components.‚Äã</p> </li> </ol> <p>This tutorial is ideal for AI developers, researchers, and enthusiasts aiming to deepen their understanding of document management and advanced natural language processing techniques. Embark on this journey to harness the power of multimodal AI and elevate your projects to new heights!‚Äã</p> <ul> <li> <p>tutorial: https://www.ibm.com/think/tutorials/build-multimodal-rag-langchain-with-docling-granite</p> </li> <li> <p>github: https://github.com/ibm-granite-community/granite-snack-cookbook/blob/main/recipes/RAG/Granite_Multimodal_RAG.ipynb</p> </li> </ul> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/7.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/7.jpg" alt="Selene"> </a> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0 text-left"> ¬© Copyright 2025 Sunder Ali Khowaja. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-82147914-4"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-82147914-4");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>for(var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.querySelectorAll('[id="WeChatBtn"]'),i=0;i<wechatBtn.length;i++)wechatBtn[i].onclick=function(){wechatModal.style.display="block"};window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-cv",title:"CV",description:"Below is a simplified version of my resume. You can find a full version in the pdf. \ud83d\udc49",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-publications",title:"Publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-blogs",title:"Blogs",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-teaching",title:"Teaching",description:"Courses and teaching activities at various institutions",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"nav-news",title:"News",description:"",section:"Navigation",handler:()=>{window.location.href="/updates/"}},{id:"post-what-is-the-technical-debt-of-large-language-models-llms-and-how-does-it-affect-us",title:"What Is the Technical Debt of Large Language Models (LLMs) and How Does...",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/What-Is-the-Technical-Debt-of-Large-Language-Models-(LLMs)-and-How-Does-It-Affect-Us/"}},{id:"post-open-source-ai-taking-forward-leaps",title:"Open Source AI taking forward leaps",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/Open-Source-AI-taking-forward-leaps/"}},{id:"post-summarizing-youtube-videos-using-python-and-online-ai-tools",title:"Summarizing YouTube Videos using Python and Online AI Tools",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/Summarizing-YouTube-Videos-using-Python-and-Online-AI-Tools/"}},{id:"post-taking-a-deep-dive-into-yolov8",title:"Taking a Deep Dive into YOLOv8",description:"Details on YOLOv8",section:"Posts",handler:()=>{window.location.href="/blog/2023/Taking-a-Deep-Dive-into-YOLOv8/"}},{id:"post-brief-timeline-of-yolo-models",title:"Brief Timeline of YOLO models",description:"Brief Timeline of YOLO models from v1 to v8",section:"Posts",handler:()=>{window.location.href="/blog/2023/Brief-Timeline-of-YOLO-models-from-v1-to-v8/"}},{id:"post-combating-urban-flooding-with-internet-of-things-and-artificial-intelligence",title:"Combating Urban flooding with Internet of Things and Artificial Intelligence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/Combating-Urban-flooding-with-Internet-of-Things-and-Artificial-Intelligence/"}},{id:"post-where-do-pakistan-stand-in-ai-race",title:"Where do Pakistan stand in AI race?",description:"A discussion on where Pakistan resides in terms of AI race.",section:"Posts",handler:()=>{window.location.href="/blog/2020/Where-do-Pakistan-stand-in-AI-race/"}},{id:"projects-best-paper-award-at-kdbc-2018",title:"Best Paper Award at KDBC 2018",description:"Our paper titled Human Action Recognition with Sequential Convolution and Recurrent Neural Networks Using 3D Skeleton Data, has won the best paper award in Korean Database Conference held at South Korea.",section:"Projects",handler:()=>{window.location.href="/projects/Best_Paper_Award_KDBC/"}},{id:"projects-first-runner-up-at-cvpr-2023-6th-ug2-challenge",title:"First Runner Up at CVPR 2023 6th UG2+ Challenge",description:"First Runner Up at CVPR 2023 6th UG2+ Challenge",section:"Projects",handler:()=>{window.location.href="/projects/UG2_FRU_Cert/"}},{id:"projects-second-runner-up-at-cvpr-2023-6th-ug2-challenge",title:"Second Runner Up at CVPR 2023 6th UG2+ Challenge",description:"Second Runner Up at CVPR 2023 6th UG2+ Challenge",section:"Projects",handler:()=>{window.location.href="/projects/UG2_SRU_Cert/"}},{id:"projects-ieee-tmi-distinguished-reviewer-bronze-level-2022-to-2023",title:"IEEE TMI Distinguished Reviewer Bronze Level 2022 to 2023",description:"IEEE TMI Distinguished Reviewer Bronze Level 2022 to 2023",section:"Projects",handler:()=>{window.location.href="/projects/TMI_reviewer/"}},{id:"projects-joined-as-ieee-consumer-technology-society-39-s-technical-committee-member",title:"Joined as IEEE Consumer Technology Society&#39;s Technical Committee Member",description:"Joined as IEEE Consumer Technology Society&#39;s Technical Committee Member",section:"Projects",handler:()=>{window.location.href="/projects/CTSoc_technical_member/"}},{id:"projects-best-paper-award-at-ieee-wcnc-2024",title:"Best Paper Award at IEEE WCNC 2024",description:"Our paper titled Zero-Trust Attack Framework with Split Learning for Autonomous Vehicles in 6G Networks, has won the best paper award at 25th IEEE Wireless Communications and Networking Conference held at Dubai, UAE",section:"Projects",handler:()=>{window.location.href="/projects/Best_Paper_Award_WCNC/"}},{id:"projects-serving-as-special-session-chair-at-ieee-gem-2024",title:"Serving as Special Session Chair at IEEE GEM 2024",description:"Call for papers in Special Session at IEEE Gaming, Entertainment and Media (GEM) conference, 2024",section:"Projects",handler:()=>{window.location.href="/projects/Chair_special_session_GEM/"}},{id:"projects-top-10-methods-at-cvpr-39-s-ntire-blind-compressed-image-enhancement-challenge",title:"Top 10 Methods at CVPR&#39;s NTIRE Blind Compressed Image Enhancement Challenge",description:"Our submission has been included in the top methods for NTIRE 2024 Blind Compressed Image Enhancement Challenge held at CVPR competitions.",section:"Projects",handler:()=>{window.location.href="/projects/NTIRE_BICE_Challenge/"}},{id:"projects-best-researcher-nomination-certificate",title:"Best Researcher Nomination Certificate",description:"Nomination Certificate for Early Career Researcher Award at Technological University (TU) Dublin, Ireland.",section:"Projects",handler:()=>{window.location.href="/projects/Best_researcher_nomination/"}},{id:"projects-daily-ai-news",title:"Daily AI news",description:"This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI",section:"Projects",handler:()=>{window.location.href="/projects/Daily_AI_News/"}},{id:"teaching-machine-learning",title:"Machine Learning",description:"2024_Machine_Learning.",section:"Teaching",handler:()=>{window.location.href="/teaching/Machine-Learning/"}},{id:"teaching-object-oriented-programming-java",title:"Object Oriented Programming (Java)",description:"2024_Object_oriented_programming_java.",section:"Teaching",handler:()=>{window.location.href="/teaching/object-oriented-programming-java/"}},{id:"teaching-object-oriented-programming-python",title:"Object Oriented Programming (Python)",description:"2024_Object_oriented_programming_python.",section:"Teaching",handler:()=>{window.location.href="/teaching/object-oriented-programming-python/"}},{id:"teaching-systems-and-network-database-administration",title:"Systems and Network Database Administration",description:"2024_Systems_Database_Administration.",section:"Teaching",handler:()=>{window.location.href="/teaching/systems-database-administration/"}},{id:"teaching-python-for-data-management",title:"Python for Data Management",description:"2024_python_for_data_management.",section:"Teaching",handler:()=>{window.location.href="/teaching/python-for-data-management/"}},{id:"teaching-program-design",title:"Program Design",description:"2024_Program_Design.",section:"Teaching",handler:()=>{window.location.href="/teaching/program-design/"}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}],console.log(ninja.data);</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>