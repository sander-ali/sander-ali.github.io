<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Daily AI news | Sunder Ali Khowaja </title> <meta name="author" content="Sunder Ali Khowaja"> <meta name="description" content="This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI"> <meta name="keywords" content="Khowaja Sunder, Sunder Ali Khowaja, Sander Ali Khowaja, dr.Sunder Ali Khowaja, doctor sunder khowaja, sunder ali, sander ali, dr sunder ali contact number, IEEE Senior Member, sunder ali usindh, sander ali usindh, deep-learning, computer-vision, AI-researcher, machine-learning, model inversion attacks, medical-imaging, private ai, neural-networks, academic-publications, research-portfolio"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img//favicon.png?5db4cf704bc2caffc10b1d53e8fa8ffd"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sander-ali.github.io/projects/Daily_AI_News/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Sunder Ali Khowaja </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blogs </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/updates/">News </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Daily AI news</h1> <p class="post-description">This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI</p> </header> <article> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/logo_SAK_15.PNG" target="_blank"> <img src="/assets/img/news/logo_SAK_15.PNG" alt="Comapny Logo"> </a> </div> </div> <h1> 26th March 2025 </h1> <h1> ☄️ GRPO now scales to 70B+ models </h1> <p>☄️ GRPO now scales to 70B+ models with multi-node training and super-fast performance. Train up to 60 times faster with all the freshest features and optimizations that we’ve added. More details in the thread below 🧵👇</p> <p>Install the latest v0.16 version of TRL.</p> <p>🐦‍🔥 GRPO is now 6x faster with multi-step optimization</p> <p>This new feature allows for the reuse of generated data across multiple optimization steps, cutting down training time significantly.</p> <p>TRL added importance sampling and clipping logic to make this possible. Set num_iterations to 4 or more for the full effect!</p> <p>🩺 Dr GRPO</p> <p>TRL integrated two major insights from Dr GRPO:</p> <p>1️⃣ Global normalization to avoid response-level length bias (no more per-sequence normalization).</p> <p>2️⃣ The option to disable reward scaling to eliminate question-level difficulty bias!</p> <p>🤸‍♀️ Domain-specific rewards</p> <p>When optimizing across multiple domains, not all rewards apply to every sample. For example, math rewards shouldn’t be given to biology samples (and vice versa).</p> <p>Now, you can return None for irrelevant rewards based on the sample’s domain!</p> <p>🍃 Save time and memory with beta=0.0</p> <p>By setting beta to 0, the reference model is not loaded, and KL divergence is not computed, leading to big savings in memory and compute while still achieving great results!</p> <p>🕊️ Padding-free batching for SFT</p> <p>This method reduces memory usage by flattening batches into a single sequence, keeping sequences intact without padding—avoiding cross-contamination seen in packing.</p> <p>Enable it by setting padding_free=True in SFTConfig.</p> <p>Increasing the upper bound epsilon, as shown in the DAPO paper, leads to higher entropy during generation, promoting better exploration.</p> <p>Now, you can easily adjust the upper bound epsilon in GRPO with <code class="language-plaintext highlighter-rouge">epsilon_high</code> for more diverse outcomes.</p> <p>More here:</p> <p>📜 Release notes: https://github.com/huggingface/trl/releases/tag/v0.16.0</p> <p>💼 PyPI: https://pypi.org/project/trl/</p> <p>🐋 OpenR1: https://github.com/huggingface/open-r1</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/1.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/1.jpg" alt="Nyx"> </a> </div> </div> <hr> <hr> <h1> 🔥🔥 Dereflecting Any Image 🔥🔥 </h1> <p>👉SJTU &amp; Huawei unveils Dereflection Any Image (DAI), novel diffusion-based framework able to recover from a wide range of reflection types. One-step diffusion with deterministic outputs and fast inference. Inference code, pretrained models &amp; training released💙</p> <p>𝐇𝐢𝐠𝐡𝐥𝐢𝐠𝐡𝐭𝐬:</p> <p>✅Proposing a novel/efficient pipeline for data collection</p> <p>✅DRR: HQ dataset w/ diverse reflections w/ varying angles</p> <p>✅New diffusion-based framework with progressive training</p> <p>✅SOTA performance also on challenging mobile captures</p> <p>👉Paper https://arxiv.org/pdf/2503.17347</p> <p>👉Project https://abuuu122.github.io/DAI.github.io/</p> <p>👉Repo https://github.com/Abuuu122/Dereflection-Any-Image</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;"> <iframe width="560" height="315" src="https://abuuu122.github.io/DAI.github.io/static/videos/demo.mp4"></iframe> </div> </div> <hr> <hr> <h1> Netflix has built a unified recommendation foundation model </h1> <p>Netflix has built a unified recommendation foundation model to replace its many specialized systems across their large-scale personalization and recommenders systems internally which drive 80% of the content discovery in their platform.</p> <p>Netflix has been able to leverage large-scale high-quality user interaction data together with advanced tokenization techniques (with inspiration from LLMs) to train a foundation model that captures long-term user behavior over extensive interaction histories.</p> <p>In their overview they also dive into their cold-start problem, and how they tackle with with a hybrid embedding strategy which combines learnable ID and metadata-based embeddings via an attention mechanism to better handle newly launched titles.</p> <p>It is interesting to see that foundation models are now seeing practical applications in growing number of industry applications.</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/3.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/3.jpg" alt="Nyx"> </a> </div> </div> <hr> <hr> <h1> MIT Media Lab researchers just introduced a neuroadaptive AI tutor </h1> <p>MIT Media Lab researchers just introduced a neuroadaptive AI tutor that personalizes learning in real time using brainwaves!</p> <p>Traditional AI tutors rely on static responses, failing to adapt to a learner’s mental state.</p> <p>𝗡𝗲𝘂𝗿𝗼𝗖𝗵𝗮𝘁 𝗰𝗼𝗺𝗯𝗶𝗻𝗲𝘀 𝗲𝗹𝗲𝗰𝘁𝗿𝗼𝗲𝗻𝗰𝗲𝗽𝗵𝗮𝗹𝗼𝗴𝗿𝗮𝗽𝗵𝘆 (𝗘𝗘𝗚) 𝘄𝗶𝘁𝗵 𝗚𝗣𝗧-𝟰, 𝗺𝗼𝗻𝗶𝘁𝗼𝗿𝗶𝗻𝗴 𝗲𝗻𝗴𝗮𝗴𝗲𝗺𝗲𝗻𝘁 𝗮𝗻𝗱 𝗮𝗱𝗷𝘂𝘀𝘁𝗶𝗻𝗴 𝗰𝗼𝗻𝘁𝗲𝗻𝘁 𝗱𝘆𝗻𝗮𝗺𝗶𝗰𝗮𝗹𝗹𝘆.</p> <ol> <li> <p>Tracked real-time brain activity with a wearable EEG headband, measuring cognitive engagement.</p> </li> <li> <p>Modified chatbot responses such as simplifying, elaborating, or changing pacing based on engagement levels.</p> </li> <li> <p>Increased cognitive engagement significantly in a study of 24 participants, outperforming standard AI tutors.</p> </li> <li> <p>Showed no immediate impact on learning outcomes, highlighting the challenge of converting engagement into retention.</p> </li> </ol> <p>Honestly as a student, I could see myself using this haha. Really neat</p> <p>I see a lot of personalized, AI-driven tutoring applications out there.</p> <p>NeuroChat is cool to me because it advances the field by dynamically adjusting content based on real-time physiological data.</p> <p>Here’s the awesome work: https://arxiv.org/abs/2503.07599</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/4.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/4.jpg" alt="Nyx"> </a> </div> </div> <hr> <hr> <h1> Real-time communication Library to build Voice AI Agents in Python!🔥 </h1> <p>Turn any python function into a real-time audio and video stream over WebRTC or WebSockets.</p> <p>Here is how it works:</p> <p>Simply write a Python function that takes in audio or video data, processes it however you want, and returns the output. FastRTC handles all the complex real-time streaming, including WebRTC and WebSocket connections, so you can focus purely on your logic.</p> <p>Key Features:</p> <p>• 🗣 Automatic Voice Detection &amp; Turn-Taking — Focus only on your response logic.</p> <p>• 💻 Built-in Gradio UI — Instantly launch a WebRTC-enabled interface with .ui.launch().</p> <p>• 🔌 WebRTC Support — Mount on a FastAPI app with .mount(app) and get a WebRTC endpoint for custom frontends.</p> <p>• ⚡ WebSocket Support — Expose a websocket endpoint just as easily with .mount(app).</p> <p>• 📞 Phone Call Support — Spin up a temporary phone number with .fastphone() and handle calls directly.</p> <p>• 🤖 Customizable Backend — Integrates seamlessly with FastAPI for production-ready applications.</p> <p>The best part?</p> <p>It’s 100% Open Source</p> <p>Github Repo: https://github.com/freddyaboulton/fastrtc</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/5.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/5.jpg" alt="Nyx"> </a> </div> </div> <hr> <hr> <h1> A billion-parameter voice AI is now open source 😳 </h1> <p>Sesame AI dropped CSM-1B - the billion-parameter engine powering the viral assistant Maya.</p> <p>This isn’t your typical tech release:</p> <ul> <li> <p>1 billion parameters</p> </li> <li> <p>Hollywood-level realism</p> </li> <li> <p>Instant use - zero fine-tuning</p> </li> <li> <p>Completely FREE for commercial use</p> </li> </ul> <p>No paywalls. No permissions. Apache 2.0 license.</p> <p>In simple terms:</p> <p>Every startup just got handed the keys to Google’s and Meta’s top-secret voice tech.</p> <p>Just think about it:</p> <p>→ AI phone reps indistinguishable from humans.</p> <p>→ Personalized assistants for every creator.</p> <p>→ Indie devs going head-to-head with ElevenLabs - with zero budget.</p> <p>Sesame just said:</p> <p>“Here’s the model. Build whatever you want.”</p> <p>No APIs. No subscription traps. No corporate gatekeepers.</p> <p>Voice is the next frontier - and now it’s FREE for all.</p> <p>Fascinating times.</p> <p>Github Repo: https://github.com/SesameAILabs/csm</p> <p>Model: https://huggingface.co/sesame/csm-1b</p> <p>Video credit: Brian Buntz</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <iframe width="560" height="315" src="https://www.youtube.com/embed/jqHNoTs4Meo?si=M6_GvMtK8CtSvm2B" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> </div> </div> <hr> <hr> <h1> DeepSeek AI dropped another 700GB file on Hugging Face with an MIT license. Incredible. </h1> <p>It casually beats all closed-source players!</p> <p>They released a new version of their DeepSeek-V3 model, simply called “DeepSeek-V3-0324”. It beats all other non-reasoning models, which are models that directly spit out an answer without taking time to ‘think’, making them useful in latency-sensitive use cases.</p> <p>They do this at a fraction of the price - the model is priced at $0.27 per 1M input tokens and $1.10 per 1M output tokens, compared to $3 and $15 respectively for Anthropic’s API for example.</p> <p>On the same day, Alibaba’s Qwen lab released a 32B VLM which is the best openly available vision-language model out there. It has an Apache 2.0 license which allows for self-hosting.</p> <p>It is showing once again that Chinese labs choose a different way of releasing things - in an open way, with (upcoming) tech reports.</p> <p>Artificial Analysis’s thread on this: https://x.com/ArtificialAnlys/status/1904467255083348244</p> <p>Model: https://huggingface.co/deepseek-ai/DeepSeek-V3-0324</p> <p>Qwen’s 32B VLM: https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/7.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/7.jpg" alt="Nyx"> </a> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0 text-left"> © Copyright 2025 Sunder Ali Khowaja. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-82147914-4"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-82147914-4");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>for(var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.querySelectorAll('[id="WeChatBtn"]'),i=0;i<wechatBtn.length;i++)wechatBtn[i].onclick=function(){wechatModal.style.display="block"};window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-cv",title:"CV",description:"Below is a simplified version of my resume. You can find a full version in the pdf. \ud83d\udc49",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-publications",title:"Publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-blogs",title:"Blogs",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-teaching",title:"Teaching",description:"Courses and teaching activities at various institutions",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"nav-news",title:"News",description:"",section:"Navigation",handler:()=>{window.location.href="/updates/"}},{id:"post-what-is-the-technical-debt-of-large-language-models-llms-and-how-does-it-affect-us",title:"What Is the Technical Debt of Large Language Models (LLMs) and How Does...",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/What-Is-the-Technical-Debt-of-Large-Language-Models-(LLMs)-and-How-Does-It-Affect-Us/"}},{id:"post-open-source-ai-taking-forward-leaps",title:"Open Source AI taking forward leaps",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/Open-Source-AI-taking-forward-leaps/"}},{id:"post-summarizing-youtube-videos-using-python-and-online-ai-tools",title:"Summarizing YouTube Videos using Python and Online AI Tools",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/Summarizing-YouTube-Videos-using-Python-and-Online-AI-Tools/"}},{id:"post-taking-a-deep-dive-into-yolov8",title:"Taking a Deep Dive into YOLOv8",description:"Details on YOLOv8",section:"Posts",handler:()=>{window.location.href="/blog/2023/Taking-a-Deep-Dive-into-YOLOv8/"}},{id:"post-brief-timeline-of-yolo-models",title:"Brief Timeline of YOLO models",description:"Brief Timeline of YOLO models from v1 to v8",section:"Posts",handler:()=>{window.location.href="/blog/2023/Brief-Timeline-of-YOLO-models-from-v1-to-v8/"}},{id:"post-combating-urban-flooding-with-internet-of-things-and-artificial-intelligence",title:"Combating Urban flooding with Internet of Things and Artificial Intelligence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/Combating-Urban-flooding-with-Internet-of-Things-and-Artificial-Intelligence/"}},{id:"post-where-do-pakistan-stand-in-ai-race",title:"Where do Pakistan stand in AI race?",description:"A discussion on where Pakistan resides in terms of AI race.",section:"Posts",handler:()=>{window.location.href="/blog/2020/Where-do-Pakistan-stand-in-AI-race/"}},{id:"projects-best-paper-award-at-kdbc-2018",title:"Best Paper Award at KDBC 2018",description:"Our paper titled Human Action Recognition with Sequential Convolution and Recurrent Neural Networks Using 3D Skeleton Data, has won the best paper award in Korean Database Conference held at South Korea.",section:"Projects",handler:()=>{window.location.href="/projects/Best_Paper_Award_KDBC/"}},{id:"projects-first-runner-up-at-cvpr-2023-6th-ug2-challenge",title:"First Runner Up at CVPR 2023 6th UG2+ Challenge",description:"First Runner Up at CVPR 2023 6th UG2+ Challenge",section:"Projects",handler:()=>{window.location.href="/projects/UG2_FRU_Cert/"}},{id:"projects-second-runner-up-at-cvpr-2023-6th-ug2-challenge",title:"Second Runner Up at CVPR 2023 6th UG2+ Challenge",description:"Second Runner Up at CVPR 2023 6th UG2+ Challenge",section:"Projects",handler:()=>{window.location.href="/projects/UG2_SRU_Cert/"}},{id:"projects-ieee-tmi-distinguished-reviewer-bronze-level-2022-to-2023",title:"IEEE TMI Distinguished Reviewer Bronze Level 2022 to 2023",description:"IEEE TMI Distinguished Reviewer Bronze Level 2022 to 2023",section:"Projects",handler:()=>{window.location.href="/projects/TMI_reviewer/"}},{id:"projects-joined-as-ieee-consumer-technology-society-39-s-technical-committee-member",title:"Joined as IEEE Consumer Technology Society&#39;s Technical Committee Member",description:"Joined as IEEE Consumer Technology Society&#39;s Technical Committee Member",section:"Projects",handler:()=>{window.location.href="/projects/CTSoc_technical_member/"}},{id:"projects-best-paper-award-at-ieee-wcnc-2024",title:"Best Paper Award at IEEE WCNC 2024",description:"Our paper titled Zero-Trust Attack Framework with Split Learning for Autonomous Vehicles in 6G Networks, has won the best paper award at 25th IEEE Wireless Communications and Networking Conference held at Dubai, UAE",section:"Projects",handler:()=>{window.location.href="/projects/Best_Paper_Award_WCNC/"}},{id:"projects-serving-as-special-session-chair-at-ieee-gem-2024",title:"Serving as Special Session Chair at IEEE GEM 2024",description:"Call for papers in Special Session at IEEE Gaming, Entertainment and Media (GEM) conference, 2024",section:"Projects",handler:()=>{window.location.href="/projects/Chair_special_session_GEM/"}},{id:"projects-top-10-methods-at-cvpr-39-s-ntire-blind-compressed-image-enhancement-challenge",title:"Top 10 Methods at CVPR&#39;s NTIRE Blind Compressed Image Enhancement Challenge",description:"Our submission has been included in the top methods for NTIRE 2024 Blind Compressed Image Enhancement Challenge held at CVPR competitions.",section:"Projects",handler:()=>{window.location.href="/projects/NTIRE_BICE_Challenge/"}},{id:"projects-best-researcher-nomination-certificate",title:"Best Researcher Nomination Certificate",description:"Nomination Certificate for Early Career Researcher Award at Technological University (TU) Dublin, Ireland.",section:"Projects",handler:()=>{window.location.href="/projects/Best_researcher_nomination/"}},{id:"projects-daily-ai-news",title:"Daily AI news",description:"This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI",section:"Projects",handler:()=>{window.location.href="/projects/Daily_AI_News/"}},{id:"teaching-machine-learning",title:"Machine Learning",description:"2024_Machine_Learning.",section:"Teaching",handler:()=>{window.location.href="/teaching/Machine-Learning/"}},{id:"teaching-object-oriented-programming-java",title:"Object Oriented Programming (Java)",description:"2024_Object_oriented_programming_java.",section:"Teaching",handler:()=>{window.location.href="/teaching/object-oriented-programming-java/"}},{id:"teaching-object-oriented-programming-python",title:"Object Oriented Programming (Python)",description:"2024_Object_oriented_programming_python.",section:"Teaching",handler:()=>{window.location.href="/teaching/object-oriented-programming-python/"}},{id:"teaching-systems-and-network-database-administration",title:"Systems and Network Database Administration",description:"2024_Systems_Database_Administration.",section:"Teaching",handler:()=>{window.location.href="/teaching/systems-database-administration/"}},{id:"teaching-python-for-data-management",title:"Python for Data Management",description:"2024_python_for_data_management.",section:"Teaching",handler:()=>{window.location.href="/teaching/python-for-data-management/"}},{id:"teaching-program-design",title:"Program Design",description:"2024_Program_Design.",section:"Teaching",handler:()=>{window.location.href="/teaching/program-design/"}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}],console.log(ninja.data);</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>