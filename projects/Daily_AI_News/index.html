<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Daily AI news | Sunder Ali Khowaja </title> <meta name="author" content="Sunder Ali Khowaja"> <meta name="description" content="This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI"> <meta name="keywords" content="Khowaja Sunder, Sunder Ali Khowaja, Sander Ali Khowaja, dr.Sunder Ali Khowaja, doctor sunder khowaja, sunder ali, sander ali, dr sunder ali contact number, IEEE Senior Member, sunder ali usindh, sander ali usindh, deep-learning, computer-vision, AI-researcher, machine-learning, model inversion attacks, medical-imaging, private ai, neural-networks, academic-publications, research-portfolio"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img//favicon.png?5db4cf704bc2caffc10b1d53e8fa8ffd"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sander-ali.github.io/projects/Daily_AI_News/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Sunder Ali Khowaja </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blogs </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/updates/">News </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Daily AI news</h1> <p class="post-description">This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI</p> </header> <article> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/logo_SAK_15.PNG" target="_blank"> <img src="/assets/img/news/logo_SAK_15.PNG" alt="Comapny Logo"> </a> </div> </div> <h1> 8th March 2025 </h1> <h1> Code Execution from Google DeepMind </h1> <p>Here is how the Code Execution from Google DeepMind Gemini 2.0 works. Code execution allows Gemini to generate and then run Python code. This enables the model to automatically perform data analysis, algorithmic tasks or solve problems that are difficult or impossible to achieve through text only.</p> <blockquote> <p>If the code throws an error it tries to auto-fix, up to 5 times.</p> </blockquote> <blockquote> <p>Supports file input: 1 million tokens = roughly 2MB (e.g. CSV)</p> </blockquote> <blockquote> <p>The maximum runtime of the code environment is 30 seconds.</p> </blockquote> <blockquote> <p>Python libraries installed: altair, chess, cv2, matplotlib, mpmath, numpy, pandas, pdfminer, reportlab, seaborn, sklearn, statsmodels, striprtf, sympy, and tabulate</p> </blockquote> <p>Docs: https://ai.google.dev/gemini-api/docs/code-execution?lang=python</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/1.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/1.jpg" alt="Gemini"> </a> </div> </div> <h1> AMD introduces Instella</h1> <p>NEW: AMD introduces Instella, a series of fully open-source, state-of-the-art 3B parameter language models.</p> <p>Itâ€™s nice to see AMD pushing out its own small language models.</p> <p>It looks like a very competitive model for its size.</p> <p>Hereâ€™s everything you need to know:</p> <p>â€¢ Architecture: Autoregressive transformer with 36 decoder layers and 32 attention heads. This is a text-only model.</p> <p>â€¢ Sequence Length: 4,096 tokens</p> <p>â€¢ Vocabulary: ~50,000 tokens (using OLMo tokenizer)</p> <p>â€¢ Training Hardware: Installa is trained entirely on AMD Instinct MI300X GPUs; specifically, 128 AMD Instinct MI300X GPUs.</p> <p>â€¢ Multi-Stage Training Pipeline: Stage 1 Pre-training: 4.065 trillion tokens covering diverse content (coding, academic, web). Stage 2 Pre-training: Additional 57.575 billion tokens, including specialized datasets for mathematics, coding, and conversational interactions.</p> <p>â€¢ Supervised Fine-Tuning (SFT): 8.9 billion tokens to enhance instruction-following capabilities. It also includes an alignment Stage (DPO): 760 million tokens for alignment to human preferences (Instella-3B-Instruct).</p> <p>â€¢ Performance Highlights: Instella-3B significantly surpasses existing fully open 3B models (+8.08% average improvement). Competes closely with leading open-weight models like Llama-3.2-3B, Gemma-2-2B, and Qwen-2.5-3B. Achieved outstanding performance improvements in benchmarks like ARC Challenge, MMLU, BBH, and GSM8K. The instruction-tuned models excel in interactive, instruction-following tasks, achieving results comparable to or surpassing open-weight models.</p> <p>â€¢ Training Optimizations: Used FlashAttention-2 for efficient attention computation, Torch Compile for performance acceleration, and Fully Sharded Data Parallelism (FSDP) for optimal resource utilization and scalability.</p> <p>â€¢ Open Source: Fully open-sourced model weights, datasets, training hyperparameters, and code available on Hugging Face and GitHub.</p> <p>â€¢ Future Directions: Plans include expanding context length, enhancing reasoning skills, exploring multimodal capabilities, and scaling up models and datasets.</p> <p>â€¢ License and Usage: Available under a ResearchRAIL license, intended for academic and research purposes only.</p> <p>Blog: https://rocm.blogs.amd.com/artificial-intelligence/introducing-instella-3B/README.html</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/2.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/2.jpg" alt="OMi"> </a> </div> </div> <h1>ğŸ”¥ğŸ”¥Distill-Any-Depth: new SOTA MDEğŸ”¥ğŸ”¥</h1> <p>ğŸ‘‰Distill-Any-Depth is the new SOTA monocular depth estimation model trained with a novel knowledge distillation. Source Code, pre-trained models &amp; Hugging Face demo releasedğŸ’™</p> <p>ğ‡ğ¢ğ ğ¡ğ¥ğ¢ğ ğ¡ğ­ğ¬:</p> <p>âœ…Authors: ZJUT, WestLake University, LZU &amp; NTU</p> <p>âœ…Multiple D-normalization on pseudo-label distillation</p> <p>âœ…Proposing novel Cross-Context Distillation approach</p> <p>âœ…Introducing new multi-teacher distillation framework</p> <p>âœ…Pre-trained Models and code released under MIT</p> <p>ğŸ‘‰Paper arxiv.org/pdf/2502.19204</p> <p>ğŸ‘‰Repo https://github.com/Westlake-AGI-Lab/Distill-Any-Depth</p> <p>ğŸ¤—Demo https://huggingface.co/spaces/xingyang1/Distill-Any-Depth</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/3.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/3.jpg" alt="Nyx"> </a> </div> </div> <h1> How good are ReAct Agents under pressure? </h1> <p>How good are ReAct Agents under pressure? ReACT (Reasoning and Acting) Agents are AI Agents that combine reasoning with tool calling, enabling them to iteratively think through problems, use tools, and act based on observations to achieve goals.</p> <p>LangChain ran benchmarks on far can we push single ReAct Agents by scaling domains (Topic Area, e.g. Customer Support) and available tools.</p> <p>Results:</p> <p>ğŸ”¬ Evaluated Tool calling trajectory (the order of the called tools) and final output with LLM as a Judge.</p> <p>ğŸ¦™ Benchmarked Claude 3.5 sonnet, gpt-4o, o1, o3-mini &amp; Llama 3.3 70B</p> <p>ğŸ§  Both more context and more tools degrade agent performance</p> <p>ğŸ“‰ Performance on tasks requiring 3+ tool calls dropped more severely than simpler tasks</p> <p>ğŸ› ï¸ o1, o3-mini, and claude-3.5-sonnet outperform gpt-4o and llama-3.3-70B, .</p> <p>ğŸ“… Calendar Scheduling: o1 (71%) and o3-mini (68%) were top performers with the base domain.</p> <p>Blog: https://blog.langchain.dev/react-agent-benchmarking/</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/4.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/4.jpg" alt="ClaudeCode"> </a> </div> </div> <h1> ğŸš¨ Breaking: Perplexity Launches Voice Mode on macOS </h1> <p>Perplexityâ€™s latest update brings voice mode to macOS, adding a new way to interact with AI. Now, you can ask questions and get answersâ€”without typing.</p> <p>ğŸ”¹Hands-free search for faster results</p> <p>ğŸ”¹Switch between voice and text seamlessly</p> <p>ğŸ”¹Stay focused without disrupting your workflow</p> <p>For those who prefer speaking over typing, this update offers a new way to explore ideas and get information.</p> <p>How do you see voice AI fitting into your daily routine? ğŸ”Š</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/5.JPG" target="_blank"> <img src="/assets/img/news/AI%20news/5.JPG" alt="Gradio"> </a> </div> </div> <h1> Exciting news from AMD </h1> <p>Exciting news from AMD! Thrilled to announce the launch of several new libraries, including our centralized repository: AITER.</p> <p>AITER is designed to accelerate AI workloads by supporting a wide range of high-performance AI operatorsâ€”all in one unified place. This repository is tailored to address various customer operator-level requests, enabling developers to concentrate on crafting operators while customers integrate these collections seamlessly into their own frameworks, whether private, public, or otherwise.</p> <p>Key Features:</p> <ul> <li> <p>C++ Level API: Robust support for high-performance computing.</p> </li> <li> <p>Python Level API: Easy-to-use interface for rapid development.</p> </li> <li> <p>Versatile Kernel Support: Underlying kernels can be sourced from triton, ck, or asm.</p> </li> <li> <p>Comprehensive Kernel Coverage: Includes not only inference kernels but also training kernels and GEMM+communication kernelsâ€”empowering any kernel+framework combination to overcome architectural limitations.</p> </li> </ul> <p>Proud to support innovation and efficiency in AI development. Check out AITER on GitHub and see how AMD is paving the way for next-generation AI performance!</p> <p>https://github.com/ROCm/aiter</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/6.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/6.jpg" alt="BirdSQL"> </a> </div> </div> <h1> ğŸš€ Big news for AI agents! </h1> <p>With the latest release of smolagents, you can now securely execute Python code in sandboxed Docker or E2B environments. ğŸ¦¾ğŸ”’</p> <p>Hereâ€™s why this is a game-changer for agent-based systems: ğŸ§µğŸ‘‡</p> <p>1ï¸âƒ£ Security First ğŸ”</p> <p>Running AI agents in unrestricted Python environments is risky! With sandboxing, your agents are isolated, preventing unintended file access, network abuse, or system modifications.</p> <p>2ï¸âƒ£ Deterministic &amp; Reproducible Runs ğŸ“¦</p> <p>By running agents in containerized environments, you ensure that every execution happens in a controlled and predictable settingâ€”no more environment mismatches or dependency issues!</p> <p>3ï¸âƒ£ Resource Control &amp; Limits ğŸš¦</p> <p>Docker and E2B allow you to enforce CPU, memory, and execution time limits, so rogue or inefficient agents donâ€™t spiral out of control.</p> <p>4ï¸âƒ£ Safer Code Execution in Production ğŸ­</p> <p>Deploy AI agents confidently, knowing that any generated code runs in an ephemeral, isolated environment, protecting your host machine and infrastructure.</p> <p>5ï¸âƒ£ Easy to Integrate ğŸ› ï¸</p> <p>With smolagents, you can simply configure your agent to use Docker or E2B as its execution backendâ€”no need for complex security setups!</p> <p>6ï¸âƒ£ Perfect for Autonomous AI Agents ğŸ¤–</p> <p>If your AI agents generate and execute code dynamically, this is a must-have to avoid security pitfalls while enabling advanced automation.</p> <p>âš¡ Get started now: https://github.com/huggingface/smolagents</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/7.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/7.jpg" alt="Selene"> </a> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0 text-left"> Â© Copyright 2025 Sunder Ali Khowaja. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-82147914-4"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-82147914-4");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>for(var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.querySelectorAll('[id="WeChatBtn"]'),i=0;i<wechatBtn.length;i++)wechatBtn[i].onclick=function(){wechatModal.style.display="block"};window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-cv",title:"CV",description:"Below is a simplified version of my resume. You can find a full version in the pdf. \ud83d\udc49",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-publications",title:"Publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-blogs",title:"Blogs",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-teaching",title:"Teaching",description:"Courses and teaching activities at various institutions",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"nav-news",title:"News",description:"",section:"Navigation",handler:()=>{window.location.href="/updates/"}},{id:"post-what-is-the-technical-debt-of-large-language-models-llms-and-how-does-it-affect-us",title:"What Is the Technical Debt of Large Language Models (LLMs) and How Does...",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/What-Is-the-Technical-Debt-of-Large-Language-Models-(LLMs)-and-How-Does-It-Affect-Us/"}},{id:"post-open-source-ai-taking-forward-leaps",title:"Open Source AI taking forward leaps",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/Open-Source-AI-taking-forward-leaps/"}},{id:"post-summarizing-youtube-videos-using-python-and-online-ai-tools",title:"Summarizing YouTube Videos using Python and Online AI Tools",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/Summarizing-YouTube-Videos-using-Python-and-Online-AI-Tools/"}},{id:"post-taking-a-deep-dive-into-yolov8",title:"Taking a Deep Dive into YOLOv8",description:"Details on YOLOv8",section:"Posts",handler:()=>{window.location.href="/blog/2023/Taking-a-Deep-Dive-into-YOLOv8/"}},{id:"post-brief-timeline-of-yolo-models",title:"Brief Timeline of YOLO models",description:"Brief Timeline of YOLO models from v1 to v8",section:"Posts",handler:()=>{window.location.href="/blog/2023/Brief-Timeline-of-YOLO-models-from-v1-to-v8/"}},{id:"post-combating-urban-flooding-with-internet-of-things-and-artificial-intelligence",title:"Combating Urban flooding with Internet of Things and Artificial Intelligence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/Combating-Urban-flooding-with-Internet-of-Things-and-Artificial-Intelligence/"}},{id:"post-where-do-pakistan-stand-in-ai-race",title:"Where do Pakistan stand in AI race?",description:"A discussion on where Pakistan resides in terms of AI race.",section:"Posts",handler:()=>{window.location.href="/blog/2020/Where-do-Pakistan-stand-in-AI-race/"}},{id:"projects-best-paper-award-at-kdbc-2018",title:"Best Paper Award at KDBC 2018",description:"Our paper titled Human Action Recognition with Sequential Convolution and Recurrent Neural Networks Using 3D Skeleton Data, has won the best paper award in Korean Database Conference held at South Korea.",section:"Projects",handler:()=>{window.location.href="/projects/Best_Paper_Award_KDBC/"}},{id:"projects-first-runner-up-at-cvpr-2023-6th-ug2-challenge",title:"First Runner Up at CVPR 2023 6th UG2+ Challenge",description:"First Runner Up at CVPR 2023 6th UG2+ Challenge",section:"Projects",handler:()=>{window.location.href="/projects/UG2_FRU_Cert/"}},{id:"projects-second-runner-up-at-cvpr-2023-6th-ug2-challenge",title:"Second Runner Up at CVPR 2023 6th UG2+ Challenge",description:"Second Runner Up at CVPR 2023 6th UG2+ Challenge",section:"Projects",handler:()=>{window.location.href="/projects/UG2_SRU_Cert/"}},{id:"projects-ieee-tmi-distinguished-reviewer-bronze-level-2022-to-2023",title:"IEEE TMI Distinguished Reviewer Bronze Level 2022 to 2023",description:"IEEE TMI Distinguished Reviewer Bronze Level 2022 to 2023",section:"Projects",handler:()=>{window.location.href="/projects/TMI_reviewer/"}},{id:"projects-joined-as-ieee-consumer-technology-society-39-s-technical-committee-member",title:"Joined as IEEE Consumer Technology Society&#39;s Technical Committee Member",description:"Joined as IEEE Consumer Technology Society&#39;s Technical Committee Member",section:"Projects",handler:()=>{window.location.href="/projects/CTSoc_technical_member/"}},{id:"projects-best-paper-award-at-ieee-wcnc-2024",title:"Best Paper Award at IEEE WCNC 2024",description:"Our paper titled Zero-Trust Attack Framework with Split Learning for Autonomous Vehicles in 6G Networks, has won the best paper award at 25th IEEE Wireless Communications and Networking Conference held at Dubai, UAE",section:"Projects",handler:()=>{window.location.href="/projects/Best_Paper_Award_WCNC/"}},{id:"projects-serving-as-special-session-chair-at-ieee-gem-2024",title:"Serving as Special Session Chair at IEEE GEM 2024",description:"Call for papers in Special Session at IEEE Gaming, Entertainment and Media (GEM) conference, 2024",section:"Projects",handler:()=>{window.location.href="/projects/Chair_special_session_GEM/"}},{id:"projects-top-10-methods-at-cvpr-39-s-ntire-blind-compressed-image-enhancement-challenge",title:"Top 10 Methods at CVPR&#39;s NTIRE Blind Compressed Image Enhancement Challenge",description:"Our submission has been included in the top methods for NTIRE 2024 Blind Compressed Image Enhancement Challenge held at CVPR competitions.",section:"Projects",handler:()=>{window.location.href="/projects/NTIRE_BICE_Challenge/"}},{id:"projects-best-researcher-nomination-certificate",title:"Best Researcher Nomination Certificate",description:"Nomination Certificate for Early Career Researcher Award at Technological University (TU) Dublin, Ireland.",section:"Projects",handler:()=>{window.location.href="/projects/Best_researcher_nomination/"}},{id:"projects-daily-ai-news",title:"Daily AI news",description:"This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI",section:"Projects",handler:()=>{window.location.href="/projects/Daily_AI_News/"}},{id:"teaching-machine-learning",title:"Machine Learning",description:"2024_Machine_Learning.",section:"Teaching",handler:()=>{window.location.href="/teaching/Machine-Learning/"}},{id:"teaching-object-oriented-programming-java",title:"Object Oriented Programming (Java)",description:"2024_Object_oriented_programming_java.",section:"Teaching",handler:()=>{window.location.href="/teaching/object-oriented-programming-java/"}},{id:"teaching-object-oriented-programming-python",title:"Object Oriented Programming (Python)",description:"2024_Object_oriented_programming_python.",section:"Teaching",handler:()=>{window.location.href="/teaching/object-oriented-programming-python/"}},{id:"teaching-systems-and-network-database-administration",title:"Systems and Network Database Administration",description:"2024_Systems_Database_Administration.",section:"Teaching",handler:()=>{window.location.href="/teaching/systems-database-administration/"}},{id:"teaching-python-for-data-management",title:"Python for Data Management",description:"2024_python_for_data_management.",section:"Teaching",handler:()=>{window.location.href="/teaching/python-for-data-management/"}},{id:"teaching-program-design",title:"Program Design",description:"2024_Program_Design.",section:"Teaching",handler:()=>{window.location.href="/teaching/program-design/"}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}],console.log(ninja.data);</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>