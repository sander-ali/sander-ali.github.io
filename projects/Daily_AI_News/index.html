<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Daily AI news | Sunder Ali Khowaja </title> <meta name="author" content="Sunder Ali Khowaja"> <meta name="description" content="This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI"> <meta name="keywords" content="Khowaja Sunder, Sunder Ali Khowaja, Sander Ali Khowaja, dr.Sunder Ali Khowaja, doctor sunder khowaja, sunder ali, sander ali, dr sunder ali contact number, IEEE Senior Member, sunder ali usindh, sander ali usindh, deep-learning, computer-vision, AI-researcher, machine-learning, model inversion attacks, medical-imaging, private ai, neural-networks, academic-publications, research-portfolio"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img//favicon.png?5db4cf704bc2caffc10b1d53e8fa8ffd"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sander-ali.github.io/projects/Daily_AI_News/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Sunder Ali Khowaja </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blogs </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/updates/">News </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Daily AI news</h1> <p class="post-description">This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI</p> </header> <article> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/logo_SAK_15.PNG" target="_blank"> <img src="/assets/img/news/logo_SAK_15.PNG" alt="Comapny Logo"> </a> </div> </div> <h1> 13th March 2025 </h1> <h1> Reka Flash 3: a 21B reasoning model with great performance </h1> <p>Reka recently open-sourced a preliminary version of Reka Flash 3, a 21 billion parameter multimodal language model designed to excel at tasks like general chat, encoding, instruction, and function calls. This compact model offers competitive performance compared to proprietary solutions like OpenAI o1-mini, making it ideal for applications that require low latency or local device deployments. Its ability to handle contexts of up to 32,000 tokens makes it particularly versatile.</p> <p>Key Points:</p> <ul> <li> <p>21 billion parameter open source model</p> </li> <li> <p>Competitive performance with proprietary solutions</p> </li> <li> <p>Support for extended contexts of up to 32,000 tokens</p> </li> <li> <p>Suitable for low latency and local device applications</p> </li> </ul> <p>Reka Flash 3‚Äôs training process was meticulous, starting with pre-training on a heterogeneous set of synthetic and publicly accessible data. Next, the model was tuned with instructions based on high-quality, curated data to improve its performance. In the final step, reinforcement learning was applied using REINFORCE Leave One-Out (RLOO), leveraging both model-based and rule-based rewards to further enhance its capabilities. Unlike models that specialize in mathematics or coding, Reka Flash 3 aims for general improvements through reinforcement learning.</p> <p>Reka Flash 3‚Äôs performance is remarkable: on AIME-2024, with a budget of 16 reasoning steps, the model demonstrated significant efficiency. Additionally, on WMT‚Äô23, it achieved a COMET score of 83.2, showing improvements over previous versions in multilingual understanding. However, as a more compact model, it may not be the ideal option for tasks that require extensive knowledge, as indicated by its MMLU-Pro score of 65.0. Therefore, it is recommended to integrate it with web search for tasks that require in-depth knowledge.</p> <p>A distinctive aspect of Reka Flash 3 is its ability to ‚Äúthink‚Äù before generating an answer, using tags to delimit the reasoning process. This mechanism allows the model to stop reasoning after a certain number of steps, while still ensuring reasonable outputs. This feature allows processing time to be managed according to predefined budgets, providing flexibility to developers.</p> <p>In terms of deployment, Reka Flash 3 is optimized for low-cost applications that require low latency or execution on local devices. At full precision, the model occupies 39 GB (fp16), but can be compressed up to 11 GB while maintaining high performance thanks to 4-bit quantization. This makes it more efficient than larger models such as the QwQ-32B, which requires 64 GB at bf16 and 18 GB with 4-bit quantization.</p> <p>It is important to note that while Reka Flash 3 was designed primarily for English, it has demonstrated some understanding of other languages. However, in some cases, the model may process English reasoning even when questions are asked in other languages, impacting the quality of the output. Additionally, the model has not undergone extensive alignment or training, suggesting room for improvement in the future.</p> <p>For those who want to test Reka Flash 3, a trial version is available on Reka Space. Additionally, the model weights are downloadable and modifiable under the Apache 2.0 license, providing developers and researchers with a powerful yet lightweight foundation on which to build custom applications.</p> <p>Reka Flash 3 represents a significant step forward in the field of multimodal language models, combining efficiency, versatility, and accessibility, opening up new opportunities for innovative applications in the AI ‚Äã‚Äãfield.</p> <p>Source: https://www.turtlesai.com/en/pages-2470/reka-flash-3-a-21b-reasoning-model-with-great</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/1.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/1.jpg" alt="Gemini"> </a> </div> </div> <h1> ü¶úü™ûLangGraph-Reflection </h1> <p>This prebuilt graph is an agent that uses a reflection-style architecture to check and improve an initial agent‚Äôs output.</p> <p>This reflection agent uses two subagents:</p> <ul> <li> <p>A ‚Äúmain‚Äù agent, which is the agent attempting to solve the users task</p> </li> <li> <p>A ‚Äúcritique‚Äù agent, which checks the main agents work and offers any critiques</p> </li> </ul> <p><code class="language-plaintext highlighter-rouge">pip install langgraph-reflection</code></p> <p>YouTube video: https://www.youtube.com/watch?v=rBWrjNyVyCA</p> <p>GitHub: https://github.com/langchain-ai/langgraph-reflection</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/2.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/2.jpg" alt="OMi"> </a> </div> </div> <h1>OpenAI just released Agents SDK for building multi-agent apps in Python ü§Ø </h1> <p>OpenAI just launched their official agents framework - if you‚Äôre an AI agent developer or builder, here‚Äôs everything you need to know (coming from a founder building their own agents platform):</p> <p>=&gt; What is it?</p> <p>OpenAI ‚ÄúAgents SDK‚Äù is an open source agents framework with a core abstraction of agents + handoffs. For example: user sends a message ‚ÄúHola, como estas?‚Äù, which gets sent to a ‚Äútriage agent‚Äù, which then routes the request to the ‚ÄúSpanish agent‚Äù instead of the ‚ÄúEnglish agent‚Äù.</p> <p>=&gt; Is OpenAI ‚ÄúAgents SDK‚Äù open source and model-agnostic?</p> <p>‚ÄúAgents SDK‚Äù is open source and can be configured to work with third parties that support the ChatCompletions API.</p> <p>However - OpenAI‚Äôs new agent tracing is not open source. To use tracing, you have to log into OpenAI‚Äôs website and view their tracing dashboard.</p> <p>Remind anyone of LangChain (OSS) + LangSmith (closed source / SaaS product)?</p> <p>Additionally, OpenAI recommends users of the ‚ÄúAgents SDK‚Äù use their new Response API (which stores message histories, similar to the Assistants API). Currently, OpenAI is the only provider that supports this API.</p> <p>=&gt; What does this mean for other agent frameworks?</p> <p>Direct competition from the model providers. As the model layer commoditizes, OpenAI is starting to make plays in the framework layer.</p> <p>=&gt; What‚Äôs the difference between OpenAI‚Äôs agents framework and other open source agents frameworks?</p> <p>Forced ‚ÄúHandoff‚Äù abstraction: Like all abstractions, useful for some use-cases, and not a great fit for others.</p> <p>State is a second-class citizen: Similar to most agents frameworks, memory and state are not first party concepts - agents in OpenAI‚Äôs Agents SDK do not have built-in support for long-term memory or context management. It‚Äôs expected that you run your agent script once, then ‚Äúthrow it away‚Äù - similar to a workflow.</p> <p>=&gt; What‚Äôs next for OpenAI?</p> <p>It makes complete sense for OpenAI to be moving up the agents stack as the model layer commoditizes - ‚ÄúAgents SDK‚Äù is just an initial step.</p> <p>My take: OpenAI‚Äôs end-game (on the developer side) is a fully hosted stateful agents service, similar to their Custom GPTs or Assistants API. I expect to see a revised version of the Assistants API launch soon, likely rebranded as an ‚ÄúAgents API‚Äù (a paid hosted service that can integrate with the open source ‚ÄúAgents SDK‚Äù).</p> <p>=&gt; Why will / won‚Äôt OpenAI win?</p> <p>The problem for OpenAI is that developers do not want model or data lock-in in their agents stack.</p> <p>Developers want to be able to move their agent state (messages, tools, user data, data sources, memories) across model providers with zero friction. This is why provider-agnostic frameworks will win out over first party options made by OpenAI (or other frontier labs).</p> <p>Imagine if you built a verticalized agent startup on the OpenAI Assistants API in 2024. Your entire app is locked into OpenAI with no escape - no Sonnet, no DeepSeek V3/R1.</p> <p>The rise of stateful agents (e.g. agents with long-term memory) makes model lock-in even more devastating.</p> <ul> <li> <p>More commentary on what makes up the ‚Äúagents stack‚Äù: https://www.letta.com/blog/ai-agents-stack</p> </li> <li> <p>The official OpenAI Agents SDK documentation: https://openai.github.io/openai-agents-python/</p> </li> <li> <p>The new Responses API spec: https://platform.openai.com/docs/api-reference/responses/create</p> </li> </ul> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/3.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/3.jpg" alt="Nyx"> </a> </div> </div> <h1> AI Innovation in Europe </h1> <p>Today the EuroHPC Joint Undertaking (EuroHPC JU) has selected six additional proposals to establish AI Factories in the EU powered by EU‚Äôs world-class network of supercomputers.</p> <p>The newly selected AI Factories will be hosted in Austria, Bulgaria, France, Germany, Poland and Slovenia, supported by a combined national and EU investment of around ‚Ç¨485 million.</p> <p>Together with the first selection of seven AI Factories, they will bring the key ingredients for AI innovation: computing power, data and talent, fully unlocking the potential of AI in Europe.</p> <p>The factories will enable AI companies, in particular SMEs and startups, as well as researchers, to enhance the training and development of large-scale trustworthy and ethical AI models.</p> <p>Find out more information: https://europa.eu/!F6KGPG</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/4.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/4.jpg" alt="ClaudeCode"> </a> </div> </div> <h1> Google is BACK!! Welcome Gemma3 </h1> <p>Google is BACK!! Welcome Gemma3 - 27B, 12B, 4B &amp; 1B - 128K context, multimodal AND multilingual! üî•</p> <p>Gemma 3 is here and its the best open non-reasoning model on LMSYS! üöÄGoogle DeepMind Gemma 3 is an open, multimodal (text + vision), multilingual LLM with a context of 128k tokens and comes in 4 sizes!</p> <p>Evals:</p> <blockquote> <p>On MMLU-Pro, Gemma 3-27B-IT scores 67.5, close to Gemini 1.5 Pro (75.8)</p> </blockquote> <blockquote> <p>Gemma 3-27B-IT achieves an Elo score of 133 in the Chatbot Arena, outperforming larger LLaMA 3 405B (1257) and Qwen2.5-70B (1257)</p> </blockquote> <blockquote> <p>Gemma 3-4B-IT is competitive with Gemma 2-27B-IT ü§Ø</p> </blockquote> <p>Multimodal:</p> <blockquote> <p>Vision understanding via a tailored SigLIP vision encoder, treating images as sequences of soft tokens</p> </blockquote> <blockquote> <p>Pan &amp; Scan (P&amp;S): An adaptive windowing algorithm segments non-square images into 896x896 crops, improving perf in high-resolution images</p> </blockquote> <p>Long Context:</p> <blockquote> <p>Supports up to 128K tokens (except for the 1B model, which supports 32K)</p> </blockquote> <blockquote> <p>Uses a 5:1 ratio of local to global attention layers to reduce KV-cache memory explosion</p> </blockquote> <blockquote> <p>Local layers have a span of 1024 tokens, while global layers handle long context</p> </blockquote> <p>Memory Efficiency:</p> <blockquote> <p>The 5:1 local-to-global attention ratio reduces KV-cache memory overhead from 60% (global-only) to less than 15%</p> </blockquote> <blockquote> <p>Quantization Aware Training (QAT) is used to provide models in int4, int4 (per-block), and switched fp8 formats, significantly reducing memory footprint</p> </blockquote> <p>Training and Distillation:</p> <blockquote> <p>Pre-trained on 14T tokens for the 27B model, with increased multilingual data</p> </blockquote> <blockquote> <p>Uses knowledge distillation with 256 logits per token, weighted by teacher probabilities</p> </blockquote> <blockquote> <p>Post-training focuses on improving math, reasoning, and multilingual abilities, with a novel approach that outperforms Gemma 2</p> </blockquote> <p>Vision Encoder Performance:</p> <blockquote> <p>Higher resolution encoders (896x896) outperform lower resolutions (256x256) on tasks like DocVQA (59.8 vs. 31.9)</p> </blockquote> <blockquote> <p>P&amp;S boosts performance on tasks involving text recognition, e.g., DocVQA improves by +8.2 points for the 4B model</p> </blockquote> <p>Long Context Scaling:</p> <blockquote> <p>Models are pre-trained on 32K sequences and scaled to 128K using RoPE rescaling with a factor of 8</p> </blockquote> <blockquote> <p>Performance degrades rapidly beyond 128K tokens, but models generalise well within this limit</p> </blockquote> <p>Try in AI Studio: https://aistudio.google.com/prompts/new_chat?model=gemma-3-27b-it</p> <p>Models: https://huggingface.co/collections/google/gemma-3-release-67c6c6f89c4f76621268bb6d</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/5.JPG" target="_blank"> <img src="/assets/img/news/AI%20news/5.JPG" alt="Gradio"> </a> </div> </div> <h1> Olympic Coder </h1> <p>Announcement by Hugging Face</p> <p>We‚Äôve kept pushing our Open-R1 project, an open initiative to replicate and extend the techniques behind DeepSeek-R1.</p> <p>And even we were mind-blown by the results we got with this latest model we‚Äôre releasing: ‚ö°Ô∏èOlympicCoder</p> <p>It‚Äôs beating Claude 3.7 on (competitive) programming ‚Äìa domain Anthropic has been historically really strong at‚Äì and it‚Äôs getting close to o1-mini/R1 on olympiad level coding with just 7B parameters!</p> <p>And the best part is that we‚Äôre open-sourcing all about its training dataset, the new IOI benchmark, and more in our Open-R1 progress report #3: https://huggingface.co/blog/open-r1/update-3</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/6.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/6.jpg" alt="BirdSQL"> </a> </div> </div> <h1> ü§ñ Can AI Truly Capture Emotion? OpenAI‚Äôs Latest Model Might </h1> <p>Sam Altman says OpenAI‚Äôs newest AI model did something unexpected‚Äîit moved him.</p> <p>When prompted to write about AI and grief, the model‚Äôs response wasn‚Äôt just well-crafted; it was deeply resonant. According to Altman, this is the first time AI-generated writing has genuinely made him pause.</p> <p>üî∏The story explored themes of loss, memory, and the fine line between imitation and true emotion.</p> <p>üî∏The model shows a striking grasp of metafiction and human sentiment.</p> <p>üî∏OpenAI hasn‚Äôt yet shared when (or if) this model will be released.</p> <p>As AI storytelling evolves, the big question remains: Can it ever go beyond simulation and truly feel?</p> <div style="display: flex; justify-content: center; align-items: center;"> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;"> <a href="/assets/img/news/AI%20news/7.jpg" target="_blank"> <img src="/assets/img/news/AI%20news/7.jpg" alt="Selene"> </a> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0 text-left"> ¬© Copyright 2025 Sunder Ali Khowaja. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-82147914-4"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-82147914-4");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>for(var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.querySelectorAll('[id="WeChatBtn"]'),i=0;i<wechatBtn.length;i++)wechatBtn[i].onclick=function(){wechatModal.style.display="block"};window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-cv",title:"CV",description:"Below is a simplified version of my resume. You can find a full version in the pdf. \ud83d\udc49",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-publications",title:"Publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-blogs",title:"Blogs",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-teaching",title:"Teaching",description:"Courses and teaching activities at various institutions",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"nav-news",title:"News",description:"",section:"Navigation",handler:()=>{window.location.href="/updates/"}},{id:"post-what-is-the-technical-debt-of-large-language-models-llms-and-how-does-it-affect-us",title:"What Is the Technical Debt of Large Language Models (LLMs) and How Does...",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/What-Is-the-Technical-Debt-of-Large-Language-Models-(LLMs)-and-How-Does-It-Affect-Us/"}},{id:"post-open-source-ai-taking-forward-leaps",title:"Open Source AI taking forward leaps",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/Open-Source-AI-taking-forward-leaps/"}},{id:"post-summarizing-youtube-videos-using-python-and-online-ai-tools",title:"Summarizing YouTube Videos using Python and Online AI Tools",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/Summarizing-YouTube-Videos-using-Python-and-Online-AI-Tools/"}},{id:"post-taking-a-deep-dive-into-yolov8",title:"Taking a Deep Dive into YOLOv8",description:"Details on YOLOv8",section:"Posts",handler:()=>{window.location.href="/blog/2023/Taking-a-Deep-Dive-into-YOLOv8/"}},{id:"post-brief-timeline-of-yolo-models",title:"Brief Timeline of YOLO models",description:"Brief Timeline of YOLO models from v1 to v8",section:"Posts",handler:()=>{window.location.href="/blog/2023/Brief-Timeline-of-YOLO-models-from-v1-to-v8/"}},{id:"post-combating-urban-flooding-with-internet-of-things-and-artificial-intelligence",title:"Combating Urban flooding with Internet of Things and Artificial Intelligence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/Combating-Urban-flooding-with-Internet-of-Things-and-Artificial-Intelligence/"}},{id:"post-where-do-pakistan-stand-in-ai-race",title:"Where do Pakistan stand in AI race?",description:"A discussion on where Pakistan resides in terms of AI race.",section:"Posts",handler:()=>{window.location.href="/blog/2020/Where-do-Pakistan-stand-in-AI-race/"}},{id:"projects-best-paper-award-at-kdbc-2018",title:"Best Paper Award at KDBC 2018",description:"Our paper titled Human Action Recognition with Sequential Convolution and Recurrent Neural Networks Using 3D Skeleton Data, has won the best paper award in Korean Database Conference held at South Korea.",section:"Projects",handler:()=>{window.location.href="/projects/Best_Paper_Award_KDBC/"}},{id:"projects-first-runner-up-at-cvpr-2023-6th-ug2-challenge",title:"First Runner Up at CVPR 2023 6th UG2+ Challenge",description:"First Runner Up at CVPR 2023 6th UG2+ Challenge",section:"Projects",handler:()=>{window.location.href="/projects/UG2_FRU_Cert/"}},{id:"projects-second-runner-up-at-cvpr-2023-6th-ug2-challenge",title:"Second Runner Up at CVPR 2023 6th UG2+ Challenge",description:"Second Runner Up at CVPR 2023 6th UG2+ Challenge",section:"Projects",handler:()=>{window.location.href="/projects/UG2_SRU_Cert/"}},{id:"projects-ieee-tmi-distinguished-reviewer-bronze-level-2022-to-2023",title:"IEEE TMI Distinguished Reviewer Bronze Level 2022 to 2023",description:"IEEE TMI Distinguished Reviewer Bronze Level 2022 to 2023",section:"Projects",handler:()=>{window.location.href="/projects/TMI_reviewer/"}},{id:"projects-joined-as-ieee-consumer-technology-society-39-s-technical-committee-member",title:"Joined as IEEE Consumer Technology Society&#39;s Technical Committee Member",description:"Joined as IEEE Consumer Technology Society&#39;s Technical Committee Member",section:"Projects",handler:()=>{window.location.href="/projects/CTSoc_technical_member/"}},{id:"projects-best-paper-award-at-ieee-wcnc-2024",title:"Best Paper Award at IEEE WCNC 2024",description:"Our paper titled Zero-Trust Attack Framework with Split Learning for Autonomous Vehicles in 6G Networks, has won the best paper award at 25th IEEE Wireless Communications and Networking Conference held at Dubai, UAE",section:"Projects",handler:()=>{window.location.href="/projects/Best_Paper_Award_WCNC/"}},{id:"projects-serving-as-special-session-chair-at-ieee-gem-2024",title:"Serving as Special Session Chair at IEEE GEM 2024",description:"Call for papers in Special Session at IEEE Gaming, Entertainment and Media (GEM) conference, 2024",section:"Projects",handler:()=>{window.location.href="/projects/Chair_special_session_GEM/"}},{id:"projects-top-10-methods-at-cvpr-39-s-ntire-blind-compressed-image-enhancement-challenge",title:"Top 10 Methods at CVPR&#39;s NTIRE Blind Compressed Image Enhancement Challenge",description:"Our submission has been included in the top methods for NTIRE 2024 Blind Compressed Image Enhancement Challenge held at CVPR competitions.",section:"Projects",handler:()=>{window.location.href="/projects/NTIRE_BICE_Challenge/"}},{id:"projects-best-researcher-nomination-certificate",title:"Best Researcher Nomination Certificate",description:"Nomination Certificate for Early Career Researcher Award at Technological University (TU) Dublin, Ireland.",section:"Projects",handler:()=>{window.location.href="/projects/Best_researcher_nomination/"}},{id:"projects-daily-ai-news",title:"Daily AI news",description:"This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI",section:"Projects",handler:()=>{window.location.href="/projects/Daily_AI_News/"}},{id:"teaching-machine-learning",title:"Machine Learning",description:"2024_Machine_Learning.",section:"Teaching",handler:()=>{window.location.href="/teaching/Machine-Learning/"}},{id:"teaching-object-oriented-programming-java",title:"Object Oriented Programming (Java)",description:"2024_Object_oriented_programming_java.",section:"Teaching",handler:()=>{window.location.href="/teaching/object-oriented-programming-java/"}},{id:"teaching-object-oriented-programming-python",title:"Object Oriented Programming (Python)",description:"2024_Object_oriented_programming_python.",section:"Teaching",handler:()=>{window.location.href="/teaching/object-oriented-programming-python/"}},{id:"teaching-systems-and-network-database-administration",title:"Systems and Network Database Administration",description:"2024_Systems_Database_Administration.",section:"Teaching",handler:()=>{window.location.href="/teaching/systems-database-administration/"}},{id:"teaching-python-for-data-management",title:"Python for Data Management",description:"2024_python_for_data_management.",section:"Teaching",handler:()=>{window.location.href="/teaching/python-for-data-management/"}},{id:"teaching-program-design",title:"Program Design",description:"2024_Program_Design.",section:"Teaching",handler:()=>{window.location.href="/teaching/program-design/"}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}],console.log(ninja.data);</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>