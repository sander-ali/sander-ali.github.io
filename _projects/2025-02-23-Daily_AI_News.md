---
layout: page
title: Daily AI news
date: 2025-03-17
description: This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI
img: assets/img/news/logo_SAK_15.PNG

images:
  lightbox2: false
  photoswipe: false
  spotlight: false
  venobox: false
---


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/logo_SAK_15.PNG"
      target="_blank">
      <img src="/assets/img/news/logo_SAK_15.PNG" 
           alt="Comapny Logo" 
           />
</a>

  </div>
</div>

<h1> 17th March 2025 </h1>

<h1> AI-first FinTech giant Klarna just filed for US IPO ğŸ˜³ </h1>

Here's why it's a game-changer for FinTech:

Klarna leads the Buy Now, Pay Later (BNPL) revolution.

â†³ Trusted by nearly 100 million users worldwide.

â†³ Partners include Sephora, Nike, and Airbnb.

Why should you care?

â†³ Klarnaâ€™s IPO will measure investor confidence in FinTech.

â†³ It's a key test in an industry facing rising competition (think Amazon & Walmart).

IPO Quick Facts:

- $2.8B revenue in 2024

- $21M net income = profitable

- Growing 24% Year-over-Year

- 93M customers globally.

- Raising $1B at a $15B valuation

- Ticker: KLAR (NYSE)

- When: Q2 2025

We can remember that Klarna experienced a massive valuation rollercoaster:

2020: $5.5B â¡ï¸ 2021: $46.5B â¡ï¸ 2021 crash: $6.5B

Now targeting $15B+ for its IPO. Big stakes, big drama ğŸ˜®â€ğŸ’¨

But today, Klarna's secret sauce is AI ğŸ¤–

AI currently Handles 2/3 of customer service, cutting response times dramatically (11 mins â¡ï¸ under 2 mins). The whole organization is now AI-first.

It will be very interesting to see how public markets with evaluate this.

So this IPO isn't just Klarna's moment - it's FinTech's tipping point.

FinTech is back ğŸš€



<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/1.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/1.jpg" 
           alt="Nyx" 
          />
</a>
  </div>
</div>

<hr>
<hr>

<h1> ğŸš€ Introducing BeeAI </h1>

ğŸš€ Introducing BeeAI: an IBM Open Source platform designed to make working with AI Agents simpler, more flexible, and more powerful.

Yesterday in San Francisco, some of my favorite colleagues from the IBM Research AI Incubation team presented the project's evolution at the AI Developer Conference organized by deeplearning ai.

With BeeAI, whether you're building your own agents or leveraging existing ones, BeeAI helps you discover, run, and compose AI agents across any framework or language.

A few highlights the team is especially proud of:

ğŸ­/ ğ—œğ˜ ğ—¶ğ˜€ ğ—™ğ—¿ğ—®ğ—ºğ—²ğ˜„ğ—¼ğ—¿ğ—¸-ğ—®ğ—´ğ—»ğ—¼ğ˜€ğ˜ğ—¶ğ—°: Connect AI agents seamlessly, regardless of their language or platform.

ğŸ®/ ğ— ğ—¼ğ—±ğ˜‚ğ—¹ğ—®ğ—¿ ğ—±ğ—²ğ˜€ğ—¶ğ—´ğ—»: Construct sophisticated multi-agent workflows using modular components.

ğŸ¯/ ğ—•ğ˜‚ğ—¶ğ—¹ğ˜-ğ—¶ğ—» ğ—±ğ—¶ğ˜€ğ—°ğ—¼ğ˜ƒğ—²ğ—¿ğ˜†: Explore a growing catalog of AI agents with an intuitive search.

ğŸ°/ ğ——ğ—²ğ˜ƒğ—²ğ—¹ğ—¼ğ—½ğ—²ğ—¿ ğ˜€ğ˜‚ğ—½ğ—½ğ—¼ğ—¿ğ˜: First-class tools for Python and TypeScript agent developers via the BeeAI Framework.

And it's open source under the Apache 2.0 license.

If you're working with agents or considering it, check out this out:

- Website: https://beeai.dev/

- Documentation: https://docs.beeai.dev/introduction/welcome

- Agent Library: https://beeai.dev/agents

- Repo: https://github.com/i-am-bee/beeai



<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/2.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/2.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1>ğŸš«OpenAI Calls for Ban on Chinese Models  </h1>

The AI race is taking a geopolitical turn as OpenAI proposes sweeping restrictions against Chinese AI labs in its submission to the Trump Administration's "AI Action Plan."

â–ªï¸OpenAI has labeled DeepSeek as "state-subsidized" and "state-controlled" despite unclear evidence

â–ªï¸The proposal specifically recommends banning "PRC-produced" models in all "Tier 1" countries

â–ªï¸OpenAI claims Chinese models pose security risks, privacy concerns, and IP theft threats

â–ªï¸They previously accused DeepSeek of "distilling" knowledge from OpenAI's models

What do you think: Is OpenAI's proposal a legitimate security measure or a competitive strategy disguised as a policy recommendation?



<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/3.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/3.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1> Litserve is the new kid on the ML deployment block </h1>

This is the best way to deploy your Machine Learning model.

(I am not exaggerating)

Litserve is the new kid on the ML deployment block.

Based on FastAPI, ğ¥ğ¢ğ­ğ¬ğğ«ğ¯ğ provides a great serving engine for any model.

âœ… Open-source

âœ… Easy to use

âœ… 2x faster than using FastAPI by yourself

âœ… Supports Batching and Streaming

âœ… GPU Autoscaling

âœ… Automatic Dockerization

... and so much more!

I am in love with it because it is so easy to use and does not make things more complicated than they already are.

The team behind the project is also very active and supportive.


ğŸ”— Check it out: https://github.com/Lightning-AI/LitServe


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/4.jpg"
      target="_blank">
      <img src="/assets/img/news/AI news/4.jpg" 
           alt="ClaudeCode" 
           />
</a>

  </div>
</div>

<hr>
<hr>

<h1> Opensource alternative to Manus AI Agent is blowing up on GitHub ğŸ¤¯  </h1>

While everyone's fighting for Manus AI Agent invites.

Meet OWL by CAMEL-AI.org, the framework that topped the opensource benchmark for general AI agents: 

1. Specialized Multi-Agent Collaboration

â†³ AI user agents break down complex tasks

â†³ Assistant agents create detailed execution strategies

â†³ Tool agents interface with external services and APIs

2. Advanced Real-World Capabilities

â†³ Autonomous research, coding, and web browsing

â†³ Runs locally on your machine for privacy

â†³ Automates complex workflows from research to execution

3. Flexible Integration Options

â†³ Supports Claude Sonnet 3.7, GPT-4o, DeepSeek, Gemini, and Ollama

â†³ Fast installation via conda or uv with Docker support

â†³ Straightforward configuration with TOML files

The best part?

It ranks 1 on the GAIA Benchmark among opensource projects.

With a 58.18 average score.

And unlike its competitors charging $20-$200 monthly, 

OWL is completely free.

No restrictions.

No invites.

No paywalls.

Just powerful autonomous AI Agents at your fingertips.

I believe AI autonomy shouldn't be locked behind exclusive access.

Or expensive subscriptions.

Have you tried OWL or any other AI agent frameworks?

What's your experience been like?

Check it out at: https://www.camel-ai.org/

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/WUSodzEgaog?si=ODQHG1F_ed9kI3Pp" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


  </div>
</div>

<hr>
<hr>

<h1> Switch to LitApi! </h1>

If you're still using FastAPI to deploy Hugging Face LLMs/VLMs - switch to LitApi!

FastAPI is a great framework for implementing RESTful APIs. 

However, it wasnâ€™t specifically designed to handle the complex requirements of serving ML models at scale. 

The team at Lightning AI is behind LitServe and LitApi to fill in that gap.

ğŸ”¹ ğ—Ÿğ—¶ğ˜ğ—”ğ—£ğ—œ builds on top of FastAPI, adapting for ML workloads, standardizes the core steps of serving a model.

ğŸ”¹ ğ—Ÿğ—¶ğ˜ğ—¦ğ—²ğ—¿ğ˜ƒğ—²ğ—¿ handles the infrastructure side of serving models.

ğŸ”¸ Here's what you must know:

1. ğ—¢ğ—»ğ—²-ğ˜ğ—¶ğ—ºğ—² ğ—ºğ—¼ğ—±ğ—²ğ—¹ ğ˜€ğ—²ğ˜ğ˜‚ğ—½

In the ğ™¨ğ™šğ™©ğ™ªğ™¥() method, we can load any model only once.

2. ğ—–ğ˜‚ğ˜€ğ˜ğ—¼ğ—ºğ—¶ğ˜‡ğ—² ğ—£ğ—¿ğ—²ğ—±ğ—¶ğ—°ğ˜

In the ğ™¥ğ™§ğ™šğ™™ğ™ğ™˜ğ™©() method, we implement the inference on inputs logic.

3. ğ—–ğ˜‚ğ˜€ğ˜ğ—¼ğ—ºğ—¶ğ˜‡ğ—² ğ—•ğ—®ğ˜ğ—°ğ—µğ—¶ğ—»ğ—´ ğ—Ÿğ—¼ğ—´ğ—¶ğ—°

You can specify a MAX_BATCH_SIZE and a BATCH_TIME_WINDOW and it'll automatically handle the dynamic batching of requests as they come in concurrently.

You can use ThreadPoolExecutor to parallelize the preprocessing steps in the ğ™—ğ™–ğ™©ğ™˜ğ™() method.

4. ğ—–ğ˜‚ğ˜€ğ˜ğ—¼ğ—ºğ—¶ğ˜‡ğ—² ğ—¨ğ—»ğ—¯ğ—®ğ˜ğ—°ğ—µğ—¶ğ—»ğ—´ ğ—Ÿğ—¼ğ—´ğ—¶ğ—°

After inferencing on a batch, you'll handle the detach () of GPU tensors and post-process the raw logits in the ğ™ªğ™£ğ™—ğ™–ğ™©ğ™˜ğ™() method.

5. ğ——ğ—²ğ—°ğ—¼ğ—±ğ—² ğ—¿ğ—²ğ—¾ğ˜‚ğ—²ğ˜€ğ˜ ğ—®ğ—»ğ—± ğ—²ğ—»ğ—°ğ—¼ğ—±ğ—² ğ—¿ğ—²ğ˜€ğ—½ğ—¼ğ—»ğ˜€ğ—²

In the ğ™™ğ™šğ™˜ğ™¤ğ™™ğ™š_ğ™§ğ™šğ™¦ğ™ªğ™šğ™¨ğ™©() - specify how the API should access the input value from the request.

In the ğ™šğ™£ğ™˜ğ™¤ğ™™ğ™š_ğ™§ğ™šğ™¨ğ™¥ğ™¤ğ™£ğ™¨ğ™š() - specify how the API should return responses to the client.

Simple as that!

To scale this up for a production workload, you'll use LitServe's scale configuration parameters:

```
LitServer(

 lit_api: LitAPI,

 accelerator: str = "auto",

 devices: Union[str, int] = "auto",

 workers_per_device: int = 1,

 timeout: Union[float, bool] = 30,

 max_batch_size: int = 1,

 batch_timeout: float = 0.0,

 stream: bool = False,

)

```

ğŸ“™ For a full tutorial, see this article: https://neuralbits.substack.com/p/a-complete-tutorial-on-litservelitapi

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/6.jpg"
      target="_blank">
      <img src="/assets/img/news/AI news/6.jpg" 
           alt="BirdSQL" 
           />
</a>

  </div>
</div>

<hr>
<hr>

<h1> Reasoning Models 2.0, combine Reasoning with Tool Use! </h1>

âœ¨ START teaches LLMs to use tools, such as code interpreter to improve reasoning and problem-solving. Self-taught Reasoner with Tools (START) integrates tool usage with chain-of-thought reasoning by enabling tool calls, self-check, exploration, and self-debug while reasoning using a self-learning framework. ğŸ‘€

Implementation

1 Collect math problems (AIME, MATH) and coding tasks (Codeforces, LiveCodeBench)

2 Create context-specific hints like "Maybe using Python here is a good idea"

3 Generate tool-assisted reasoning data (insert hints after conjunctions like "Wait" and before stop tokens)

4 Score trajectories, remove repetitive patterns, and create a seed dataset with successful tool-assisted reasoning examples.

5 Fine-tune model on seed dataset, then self self-Distill to generate more diverse reasoning trajectories

6 Fine-tune the base model using rejection sampling (RFT) on the extended dataset

Insights

ğŸ’¡ Improves math accuracy by +15% (AMC23: 95.0%) and coding by +38.6% on medium problems.

ğŸ“ˆ Test-time scaling via sequential hints boosts AIME24 performance by 12%.

ğŸ Code template modification reduces debug errors by 41% in training data.

ğŸ’¡ Adding tools (Python interpreter) improves performance more than adding more training data.

ğŸ§  Large models already possess latent tool-using abilities that can be activated through hints.

ğŸ› ï¸ Two-phase training (Hint-RFT then RFT) allows the model to learn effective tool usage.

ğŸ“ Hint place selection is important. After conjunction Token and before stop token.

Paper: https://huggingface.co/papers/2503.04625

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/7.jpg"
      target="_blank">
      <img src="/assets/img/news/AI news/7.jpg" 
           alt="Selene" 
           />
</a>

  </div>
</div>
