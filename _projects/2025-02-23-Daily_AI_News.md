---
layout: page
title: Daily AI news
date: 2025-03-29
description: This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI
img: assets/img/news/logo_SAK_15.PNG

images:
  lightbox2: false
  photoswipe: false
  spotlight: false
  venobox: false
---


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/logo_SAK_15.PNG"
      target="_blank">
      <img src="/assets/img/news/logo_SAK_15.PNG" 
           alt="Comapny Logo" 
           />
</a>

  </div>
</div>

<h1> 29th March 2025 </h1>

<h1> Qwen lab at Alibaba just dropped Qwen 2.5 7B Omni 🔥   </h1>

Qwen lab at Alibaba just dropped Qwen 2.5 7B Omni 🔥 
is this AGI? 👀 

> image, video, audio, text input, audio and text output 🥹 Apache 2.0 licensed!

> outperforms Gemini 1.5 Pro in OmniBench ✨

> available in Hugging Face transformers from get-go 🤗

Model: https://huggingface.co/collections/Qwen/qwen25-omni-67de1e5f0f9464dc6314b36e 

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;">
      <a href="/assets/img/news/AI news/1.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/1.jpg" 
           alt="Nyx" 
          />
</a>
  </div>
</div>

<hr>
<hr>

<h1> Grok Released PlayAI </h1>

Groq and PlayAI announced a partnership today to bring Dialog, an advanced text-to-speech model, to market through Groq’s high-speed inference platform.

The partnership combines PlayAI’s expertise in voice AI with Groq’s specialized processing infrastructure, creating what the companies claim is one of the most natural-sounding and responsive text-to-speech systems available.

“Groq provides a complete, low latency system for automatic speech recognition (ASR), GenAI, and text-to-speech, all in one place,” said Ian Andrews, Chief Revenue Officer at Groq, in an exclusive interview with VentureBeat. “With Dialog now running on GroqCloud, this means customers won’t have to use multiple providers for a single use case — Groq is a one stop solution.”

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/jSWhgD5l8gk?si=Fsdx594YV_dOg8wI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


  </div>
</div>

<hr>
<hr>

<h1> 🦎🦎Scaling Vision Pre-Training to 4K🦎🦎 </h1>

👉PS3 by Nvidia (+UC Berkeley) to scale-up CLIP-style vision pre-training to 4K w/ *near-constant* cost. Encoding LR global image and selectively processes only informative HR regions. PS3->SOTA MLLM, and a new 4K benchmark. Impressive work. Code/weights & 🤗 announced💙

𝐇𝐢𝐠𝐡𝐥𝐢𝐠𝐡𝐭𝐬:

✅PS3 to scale CLIP-style vision pre-training to 4K

✅Scaling to 4K resolution with near-constant cost

✅Local hi-res regions based on saliency/relevance

✅VILA-HD -> extension to MLLM visual perception

✅Outperforming MLLMs such as NVILA/Qwen2-VL

Paper: https://arxiv.org/pdf/2503.19903

Project: https://nvlabs.github.io/PS3/

Repo: https://github.com/NVLabs/PS3/


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/3.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/3.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1>  Open AI Supports MCP </h1>

🚀OpenAI: You can now connect your Model Context Protocol servers to Agents

Key highlights:

1️⃣Universal Compatibility: MCP enables AI models to connect with diverse tools and data sources, amplifying their potential.

2️⃣Flexible Deployment: Choose between local (stdio) and remote (HTTP over SSE) servers for maximum flexibility.

3️⃣Efficient Performance: Automatic caching reduces latency, ensuring smoother operations.

4️⃣Transparent Insights: Comprehensive tracing provides deep insights into AI interactions. 

What innovative applications of MCP do you foresee transforming industries in the years to come?

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/4.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/4.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1> 🚀Breaking: Google DeepMind Revolutionizes Therapeutic Development with TxGemma </h1>

Google DeepMind has just unveiled TxGemma, a groundbreaking collection of open models designed to accelerate therapeutic development by leveraging large language models. 

Key highlights of TxGemma:

1️⃣Versatile Models: TxGemma offers models in three sizes (2B, 9B, and 27B) for tasks like classification, regression, and generation, enhancing predictive capabilities in therapeutic research.

2️⃣Conversational Insights: The 'chat' versions of TxGemma enable researchers to engage in multi-turn discussions, providing explanations for predictions and fostering deeper insights.

3️⃣Customization: Developers can fine-tune TxGemma using their proprietary data, allowing for tailored models that improve prediction accuracy in clinical trials.

What potential applications of TxGemma do you think could have the most profound impact on healthcare?


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/mlXIFgWIJ6s?si=B_S-yRB7UYN5MHM8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


  </div>
</div>

<hr>
<hr>

<h1> Deploying Gemma3 </h1>

You can deploy Google DeepMind Gemma 3 with just 3 lines of code to Google Cloud Vertex AI! The new Model Garden SDK abstracts away the underlying infrastructure setup, making open model deployment incredibly simple. 👀

Notebook: https://github.com/GoogleCloudPlatform/generative-ai/blob/main/open-models/get_started_with_model_garden_sdk.ipynb 

See the Image below:

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/6.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/6.jpg" 
           alt="Nyx" 
          />
</a>


  </div>
</div>

<hr>
<hr>

<h1> 📢 Microsoft 365 Copilot Introduces Researcher Agent ✨ </h1>

Researcher combines advanced reasoning models with Copilot Chat’s web- and work-grounding capabilities to perform high-value cognitive work.

Unlock new use cases like:

✅ Producing market analysis and strategy documents

✅ Creating detailed risk assessments

✅ Onboarding to a new company

📽️ Check out the demo 👇 

🛣️ Researcher is coming soon
 
 🔗 Learn more about Researcher here: https://www.microsoft.com/en-us/microsoft-365/blog/2025/03/25/introducing-researcher-and-analyst-in-microsoft-365-copilot/

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
   <iframe width="560" height="315" src="https://www.youtube.com/embed/lfruwkpqvk4?si=LhGR8BSelIYIradv" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

  </div>
</div>
