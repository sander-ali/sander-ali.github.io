---
layout: page
title: Daily AI news
date: 2025-04-04
description: This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI
img: assets/img/news/logo_SAK_15.PNG

images:
  lightbox2: false
  photoswipe: false
  spotlight: false
  venobox: false
---

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/logo_SAK_15.PNG"
      target="_blank">
      <img src="/assets/img/news/logo_SAK_15.PNG" 
           alt="Comapny Logo" 
           />
</a>
    
  </div>
</div>

<h1> 4th April 2025 </h1>

<hr>
<hr>

<h1> MCP x Gemini x LangGraph  </h1>

MCP x Gemini x LangGraph! Here is a 60 line Python Google DeepMind Gemini 2.5 Pro multi-MCP Server (remote/stdio) Agent with LangChain LangGraph ReAct. Time to build!

Code: https://github.com/philschmid/gemini-samples/blob/main/scripts/gemini-mcp-agent.py

Working on a detail guide on how you can build your own MCP Server too! 🫡

Post and code credit: Philipp Schmid


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/1.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/1.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1> 📽️ Automated filmmaking/digital human is the future </h1>

Thrilled to introduce **☕MoCha: Towards Movie-Grade Talking Character Synthesis**

- ⭐ We define a new task—Talking Characters—that generates lifelike character animations directly from natural language + speech input.

- ⭐ Our proposed model, ☕MoCha, is the first DiT-based system capable of producing cinema-quality talking characters.

- ⭐ For the first time, ☕MoCha enables **multi-character conversations with turn-based dialogue** and expressive motion, pushing the frontier of automated, AI-powered storytelling.

Project Page: https://congwei1230.github.io/MoCha/

Paper: https://arxiv.org/pdf/2503.23307

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/2.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/2.jpg" 
           alt="Nyx" 
          />
</a>
  </div>
</div>


<hr>
<hr>

<h1>  OpenAI’s GPT-4o Image Generation is here </h1>

OpenAI’s GPT-4o Image Generation debuts with an ELO score in equal first-place in the Artificial Analysis Image Arena, outperforming Recraft V3, FLUX 1.1 [pro] and Gemini 2.0 Flash

OpenAI last week launched GPT-4o Image Generation, upgrading ChatGPT’s built-in image generation from the previous system that used OpenAI’s DALL-E dedicated image generator.

GPT-4o Image Generation supports both text and image prompt input, allowing image editing with instruction prompting. In our category breakdowns, the model excels particularly at Text & Typography, People: Portraits, Anime and SciFi whereby it holds the top ranking.

OpenAI has disclosed that 4o Image Generation is an “autoregressive model natively embedded” within the GPT-4o model used by ChatGPT. However, in their launch ‘demo’ images, OpenAI hints at a hybrid architecture. This could look like an autoregressive transformer generating latent space representations, which are then converted into pixels using diffusion techniques.

OpenAI first demonstrated GPT-4o’s ability to output images in May 2024 when GPT-4o was first launched. Google beat OpenAI to a public release of native image generation capability in a modern language model with their Gemini 2.0 Flash native image generation in early March. However, Gemini 2.0 Flash is ranked 27th to GPT-4o’s 2nd in Image Arena. 

Beyond image generation, we have anecdotally found Gemini 2.0 Flash to be better than GPT-4o for certain image editing tasks where keeping an input image consistent is critical.

Leaderboard:
https://artificialanalysis.ai/text-to-image/arena?tab=Leaderboard

Link to participate in the arena:
https://artificialanalysis.ai/text-to-image/arena?tab=Arena


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/3.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/3.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1>  🚨 BOOM! The UAE is not joking around! </h1>

The city of Abu Dhabi has just allocated 3.3 billion USD to become the world's first fully AI-native city by 2027.

The government have established a Digital Strategy 2025-2027 that is putting AED 13 billion behind this mission. Key highlights:

- 100% automation of government processes

- 2,000+ digital services running on AI

- 200+ AI solutions deployed across all sectors

- AED 24 billion added to GDP

- 5,000+ new jobs created by 2027

- 80% faster service delivery with predictive AI

But this isn’t just about efficiency. This is a blueprint for the future.

Abu Dhabi is rewriting the playbook on how economies grow, how societies evolve, and how governments serve. 



<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/4.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/4.jpg" 
           alt="Nyx" 
          />
</a>


  </div>
</div>

<hr>
<hr>

<h1>  Orai: AI Speech Coach </h1>

🚀 Exciting news: Danish Dhamani is pivoting Orai: AI Speech Coach into an AI-powered dating coach!

After years of working in AI, Danish Dhamani has realized where the real demand is—not enterprise solutions, not public speaking, but helping people decode text messages and avoid getting ghosted.

Introducing OraiRomance™—the first AI-powered dating optimization tool.

🔹 Are they “haha-ing” your texts too much? We’ll analyze if you’re in the dreaded "Just a Friend" zone.

 🔹 He took 3 hours to respond—what does it mean? Our neural network detects if he’s “busy” or just… busy with someone else.

 🔹 Should you send a double text? Our AI simulates 500 parallel timelines to predict the outcome (spoiler: don’t).

Forget ChatGPT for work. This is the AI that actually matters.


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
   <a href="/assets/img/news/AI news/5.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/5.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1> TAU-bench evaluates Agents in real-world environments  </h1>

TAU-bench evaluates Agents in real-world environments and showed poor reliability. It tests if an agent can reliably engage in a dynamic, multi-turn conversation with a user to figure out what needs to be done. 

T-bench:

1️⃣ Agent interacts with an simulated user to understand needs & gather info over multiple turns.

2️⃣ Agent utilizes domain-specific API tools (e.g., book flight, return item)

3️⃣ Agent must adhere to a provided policy document containing domain-specific rules and restrictions.

4️⃣ Success is measured by comparing the final database state

5️⃣ Uses the pass^k metric to evaluate reliability on the same task over multiple (k) trials.

Insights

- 📉 At release agents succeeding less than 50% of the time.

- 🧮 Includes 10-15 tools across 50-115 different tasks for a retail and airline domain.

- 🤷 Agents are inconsistent, failing on tasks they previously succeeded on, low pass^k scores (pass^8 < 25%).

- 📊 Tasks requiring 4+ database writes have only ~20% success rate vs. ~75% for single-action tasks.

- 🚧 Failures stem from poor reasoning about database states, misunderstanding or ignoring rules (policy adherence), or mishandling complex multi-step requests.

- 📝 Removing domain guidelines drops performance by 22% in complex domains.

- 🛠️ Function calling outperforms text-based ReAct and Act-only methods.
- 📊 Evaluation is automated and compared to a final database state.

Paper: https://huggingface.co/papers/2406.12045

Github: https://github.com/sierra-research/tau-bench

Note: This benchmark was released in June 2024, but feels more important than ever. Not only it describes the limitation we currently face it also demonstrates how to setup a good evaluation pipeline for your own agents!

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/6.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/6.jpg" 
           alt="Nyx" 
          />
</a>


  </div>
</div>

<hr>
<hr>

<h1>💃💃 Video Motion Graphs 💃💃 </h1>

👉Adobe unveils a novel system designed to generate realistic human motion videos. Using a reference video & conditional signals such as music or motion tags, the system synthesizes amazing new videos. Code & Models to be released💙

𝐇𝐢𝐠𝐡𝐥𝐢𝐠𝐡𝐭𝐬:

✅Gen-system for general human motion videos

✅Real-time video generation and keyframe editing

✅SOTA performance in generating high-quality clip

✅HMInterp: HQ motion-aware video interpolation

👉Paper: https://arxiv.org/pdf/2503.20218

👉Project: https://h-liu1997.github.io/Video-Motion-Graphs/

👉Repo: TBA


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">

	<video width="320" height="240" controls>
  <source src="https://h-liu1997.github.io/Video-Motion-Graphs/comp_with_pika_luma.mp4" type="video/mp4">
</video>
  </div>
</div>
