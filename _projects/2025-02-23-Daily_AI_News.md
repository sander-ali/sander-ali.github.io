---
layout: page
title: Daily AI news
date: 2025-03-02
description: This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI
img: assets/img/news/logo_SAK_15.PNG

images:
  lightbox2: false
  photoswipe: false
  spotlight: false
  venobox: false
---


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/logo_SAK_15.PNG"
      target="_blank">
      <img src="/assets/img/news/logo_SAK_15.PNG" 
           alt="Comapny Logo" 
           />
</a>

  </div>
</div>

<h1> 2nd March 2025 </h1>

<h1> DeepSeek Profits </h1>

This is wild! DeepSeek just announced they are making $200 million/year at a 545% profit margin 😳

That makes them one of the most profitable AI businesses in the world now.

DeepSeek's reported $200M annual revenue and 500%+ profit margin stem from its efficient use of NVIDIA H800 GPUs, costing $87,000 daily, while charging significantly lower rates - $2.19 per million tokens.

To put this into perspective, OpenAI's o1 charges about 25x more while OpenAI is bleeding money 😬

The best part?

All of this is open-source while OpenAI charges $200/month and still gives you limited functionalities.

DeepSeek is truly built differently.

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/1.jpg"
      target="_blank">
      <img src="/assets/img/news/AI news/1.jpg" 
           alt="DeepSeek" 
            />
</a>

  </div>
</div>


<h1> Omi AI Wearable </h1>

🎙️🤖 Omi AI Wearable

An open-source wearable device that transforms conversations into real-time transcriptions using LangChain's AI capabilities. Features on-device processing and full iOS/Android support.

Check out Omi now! 🚀

https://github.com/BasedHardware/omi

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/2.jpg"
      target="_blank">
      <img src="/assets/img/news/AI news/2.jpg" 
           alt="OMi" 
            />
</a>

  </div>
</div>


<h1>People Being Polite to AI</h1>

🤖 Why Are People Polite to AI? A New Survey Has Answers

A recent survey reveals that while most users are polite to AI, their reasons vary—from habit to unexpected concerns about the future.

🔹70% of AI users say they are consistently polite

🔹Two-thirds of impolite users say they skip manners for brevity

🔹12% admit to being polite out of fear of a future AI uprising

As AI becomes more integrated into daily life, how much does human behavior toward machines matter?


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/3.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/3.jpg" 
           alt="Graphiti" 
          />
</a>

  </div>
</div>


<h1> LlamaExtract </h1>

LLMs are automating data ETL end-to-end - and it starts with structured extraction.

LlamaIndex is excited to announce the launch of LlamaExtract 🧑‍🔬🤖: a GenAI-native extraction agent that adapts the latest models to offer accurate structured extraction over large amounts of complex unstructured data (w/ tables, images, charts) across any document type (financial report, resumes, contracts, slides).

You can do the following:
1. Define the schema in UI or via API to define an extraction agent, and specify different parsing/config modes to use LlamaParse to process complex data.

2. Upload a ton of data, get back results, use it in your downstream workflows.

FAQ: What’s the difference between this and just prompting OpenAI/Claude/Gemini with Pydantic?

* Parsing Accuracy: We use LlamaParse under the hood to make sure that all your tables/charts are represented well - otherwise you’re going to get hallucinated values. 

* Extraction Accuracy: We also carefully tune and adapt the prompts with SOTA models with retries. We have a bunch of measures in place to make sure your schemas are valid. 

* Templates: We offer pre-built templates e.g. invoices/resumes

* UI: Have developers or business users define extraction agents, reuse it for any sort of downstream data.

* Plus a lot more goodies down the road, including integrating with existing knowledge bases + integrations. Our goal is to make sure you have the best extraction experience possible

Huge shoutout to Neeraj Pradhan for leading this effort. 

Blog: https://www.llamaindex.ai/blog/introducing-llamaextract-unlocking-structured-data-extraction-in-just-a-few-clicks

If you’re interested in trying out LlamaExtract, signup for an account: 
https://cloud.llamaindex.ai/login

If you’re interested in structured extraction in the enterprise, come talk to them: https://www.llamaindex.ai/contact


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/4.jpg"
      target="_blank">
      <img src="/assets/img/news/AI news/4.jpg" 
           alt="LlamaExtract" 
           />
</a>

  </div>
</div>

<h1> Gemini Model update </h1>

Model Update! Google DeepMind Gemini 2.0 Flash-Lite is now generally available for production use! Model ID: `gemini-2.0-flash-lite`

💰Free-Tier with 1500 req/day then $0.075/$0.3 per 1M input/output token

⚡Outperforms Gemini 1.5 Flash across benchmarks

📏 Supports 1 million input tokens and Structured Outputs

🚀 Rate Limits: Tier 1 (Paid Use) 4,000 Request per minute (if you need more let us know)

Try it: http://aistudio.google.com/?model=gemini-2.0-flash-lite

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/5.JPG"
      target="_blank">
      <img src="/assets/img/news/AI news/5.JPG" 
           alt="Google Gemini" 
          />
</a>

  </div>
</div>

<h1> IBM to Acquire DataStax </h1>

Message from Chairman and CEO at DataStax

I’m excited to share that IBM plans to acquire DataStax to accelerate production AI and NoSQL data at scale.

I’ve had the awesome privilege to be part of the DataStax journey for the last 5+ years and I couldn’t be more excited for our next chapter. We have long said that there is no AI without data, and this vision will now be amplified with IBM.

Why I continue to be PUMPED:

▪︎ With IBM, we’ll continue to unlock enterprise data to power AI agents and LLMs, accelerating adoption with scalable, secure, and accurate production AI.

▪︎ Combining DataStax’s hybrid vector database and Langflow developer tool with IBM’s watsonx will deliver cutting-edge vector and AI search across the entire data estate, making IBM’s capabilities available to every developer.

▪︎ We’ve advanced Apache Cassandra into the cloud with Astra DB and brought self-managed Cassandra into the cloud-native era with HCD and Mission Control. We’ll continue making Cassandra the standard for scaling-out your cloud-native data.

While our mission remains the same, we look forward to expanding to a much broader audience with the support of IBM.

A huge thank you to our customers, partners, and communities who have been part of this journey. It’s truly a privilege to work with all of you. 🙏

Read more: https://dtsx.io/4kfojYc

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/6.jpg"
      target="_blank">
      <img src="/assets/img/news/AI news/6.jpg" 
           alt="BirdSQL" 
           />
</a>

  </div>
</div>

<h1> Selene by Atla is live </h1>

Testing is believing.

Be among the first to try our new full-size model in the Selene Playground (official model & platform launch soon). Run evals on random samples or upload your annotated test cases to compare Selene against other language models (GPT series, Claude, etc.) on accuracy.

🧪 We tested Selene against Claude 3.5 Sonnet using a sample from the human-annotated FLASK dataset, evaluated on ‘logical robustness’ — a difficult metric that assesses whether the model output ensures general applicability and avoids logical contradictions. In this test, Selene beat Claude 3.5 Sonnet by over 15%.

Give it a go: https://huggingface.co/spaces/AtlaAI/selene

Get in touch with us if we do worse than other models and we'll send you free Atla swag (seriously).

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/7.jpg"
      target="_blank">
      <img src="/assets/img/news/AI news/7.jpg" 
           alt="Selene" 
           />
</a>

  </div>
</div>
