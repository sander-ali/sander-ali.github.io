---
layout: page
title: Daily AI news
date: 2025-03-29
description: This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI
img: assets/img/news/logo_SAK_15.PNG

images:
  lightbox2: false
  photoswipe: false
  spotlight: false
  venobox: false
---


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/logo_SAK_15.PNG"
      target="_blank">
      <img src="/assets/img/news/logo_SAK_15.PNG" 
           alt="Comapny Logo" 
           />
</a>

  </div>
</div>

<h1> 29th March 2025 </h1>

<h1> Qwen lab at Alibaba just dropped Qwen 2.5 7B Omni ğŸ”¥   </h1>

Qwen lab at Alibaba just dropped Qwen 2.5 7B Omni ğŸ”¥ 
is this AGI? ğŸ‘€ 

> image, video, audio, text input, audio and text output ğŸ¥¹ Apache 2.0 licensed!

> outperforms Gemini 1.5 Pro in OmniBench âœ¨

> available in Hugging Face transformers from get-go ğŸ¤—

Model: https://huggingface.co/collections/Qwen/qwen25-omni-67de1e5f0f9464dc6314b36e 

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;">
      <a href="/assets/img/news/AI news/1.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/1.jpg" 
           alt="Nyx" 
          />
</a>
  </div>
</div>

<hr>
<hr>

<h1> Grok Released PlayAI </h1>

Groq and PlayAI announced a partnership today to bring Dialog, an advanced text-to-speech model, to market through Groqâ€™s high-speed inference platform.

The partnership combines PlayAIâ€™s expertise in voice AI with Groqâ€™s specialized processing infrastructure, creating what the companies claim is one of the most natural-sounding and responsive text-to-speech systems available.

â€œGroq provides a complete, low latency system for automatic speech recognition (ASR), GenAI, and text-to-speech, all in one place,â€ said Ian Andrews, Chief Revenue Officer at Groq, in an exclusive interview with VentureBeat. â€œWith Dialog now running on GroqCloud, this means customers wonâ€™t have to use multiple providers for a single use case â€” Groq is a one stop solution.â€

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/jSWhgD5l8gk?si=Fsdx594YV_dOg8wI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


  </div>
</div>

<hr>
<hr>

<h1> ğŸ¦ğŸ¦Scaling Vision Pre-Training to 4KğŸ¦ğŸ¦ </h1>

ğŸ‘‰PS3 by Nvidia (+UC Berkeley) to scale-up CLIP-style vision pre-training to 4K w/ *near-constant* cost. Encoding LR global image and selectively processes only informative HR regions. PS3->SOTA MLLM, and a new 4K benchmark. Impressive work. Code/weights & ğŸ¤— announcedğŸ’™

ğ‡ğ¢ğ ğ¡ğ¥ğ¢ğ ğ¡ğ­ğ¬:

âœ…PS3 to scale CLIP-style vision pre-training to 4K

âœ…Scaling to 4K resolution with near-constant cost

âœ…Local hi-res regions based on saliency/relevance

âœ…VILA-HD -> extension to MLLM visual perception

âœ…Outperforming MLLMs such as NVILA/Qwen2-VL

Paper: https://arxiv.org/pdf/2503.19903

Project: https://nvlabs.github.io/PS3/

Repo: https://github.com/NVLabs/PS3/


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/3.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/3.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1>  Open AI Supports MCP </h1>

ğŸš€OpenAI: You can now connect your Model Context Protocol servers to Agents

Key highlights:

1ï¸âƒ£Universal Compatibility: MCP enables AI models to connect with diverse tools and data sources, amplifying their potential.

2ï¸âƒ£Flexible Deployment: Choose between local (stdio) and remote (HTTP over SSE) servers for maximum flexibility.

3ï¸âƒ£Efficient Performance: Automatic caching reduces latency, ensuring smoother operations.

4ï¸âƒ£Transparent Insights: Comprehensive tracing provides deep insights into AI interactions. 

What innovative applications of MCP do you foresee transforming industries in the years to come?

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/4.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/4.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1> ğŸš€Breaking: Google DeepMind Revolutionizes Therapeutic Development with TxGemma </h1>

Google DeepMind has just unveiled TxGemma, a groundbreaking collection of open models designed to accelerate therapeutic development by leveraging large language models. 

Key highlights of TxGemma:

1ï¸âƒ£Versatile Models: TxGemma offers models in three sizes (2B, 9B, and 27B) for tasks like classification, regression, and generation, enhancing predictive capabilities in therapeutic research.

2ï¸âƒ£Conversational Insights: The 'chat' versions of TxGemma enable researchers to engage in multi-turn discussions, providing explanations for predictions and fostering deeper insights.

3ï¸âƒ£Customization: Developers can fine-tune TxGemma using their proprietary data, allowing for tailored models that improve prediction accuracy in clinical trials.

What potential applications of TxGemma do you think could have the most profound impact on healthcare?


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/mlXIFgWIJ6s?si=B_S-yRB7UYN5MHM8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


  </div>
</div>

<hr>
<hr>

<h1> Deploying Gemma3 </h1>

You can deploy Google DeepMind Gemma 3 with just 3 lines of code to Google Cloud Vertex AI! The new Model Garden SDK abstracts away the underlying infrastructure setup, making open model deployment incredibly simple. ğŸ‘€

Notebook: https://github.com/GoogleCloudPlatform/generative-ai/blob/main/open-models/get_started_with_model_garden_sdk.ipynb 

See the Image below:

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/6.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/6.jpg" 
           alt="Nyx" 
          />
</a>


  </div>
</div>

<hr>
<hr>

<h1> ğŸ“¢ Microsoft 365 Copilot Introduces Researcher Agent âœ¨ </h1>

Researcher combines advanced reasoning models with Copilot Chatâ€™s web- and work-grounding capabilities to perform high-value cognitive work.

Unlock new use cases like:

âœ… Producing market analysis and strategy documents

âœ… Creating detailed risk assessments

âœ… Onboarding to a new company

ğŸ“½ï¸ Check out the demo ğŸ‘‡ 

ğŸ›£ï¸ Researcher is coming soon
 
 ğŸ”— Learn more about Researcher here: https://www.microsoft.com/en-us/microsoft-365/blog/2025/03/25/introducing-researcher-and-analyst-in-microsoft-365-copilot/

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
   <iframe width="560" height="315" src="https://www.youtube.com/embed/lfruwkpqvk4?si=LhGR8BSelIYIradv" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

  </div>
</div>
