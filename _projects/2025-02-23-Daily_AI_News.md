---
layout: page
title: Daily AI news
date: 2025-03-17
description: This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI
img: assets/img/news/logo_SAK_15.PNG

images:
  lightbox2: false
  photoswipe: false
  spotlight: false
  venobox: false
---


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/logo_SAK_15.PNG"
      target="_blank">
      <img src="/assets/img/news/logo_SAK_15.PNG" 
           alt="Comapny Logo" 
           />
</a>

  </div>
</div>

<h1> 17th March 2025 </h1>

<h1> AI-first FinTech giant Klarna just filed for US IPO 😳 </h1>

Here's why it's a game-changer for FinTech:

Klarna leads the Buy Now, Pay Later (BNPL) revolution.

↳ Trusted by nearly 100 million users worldwide.

↳ Partners include Sephora, Nike, and Airbnb.

Why should you care?

↳ Klarna’s IPO will measure investor confidence in FinTech.

↳ It's a key test in an industry facing rising competition (think Amazon & Walmart).

IPO Quick Facts:

- $2.8B revenue in 2024

- $21M net income = profitable

- Growing 24% Year-over-Year

- 93M customers globally.

- Raising $1B at a $15B valuation

- Ticker: KLAR (NYSE)

- When: Q2 2025

We can remember that Klarna experienced a massive valuation rollercoaster:

2020: $5.5B ➡️ 2021: $46.5B ➡️ 2021 crash: $6.5B

Now targeting $15B+ for its IPO. Big stakes, big drama 😮‍💨

But today, Klarna's secret sauce is AI 🤖

AI currently Handles 2/3 of customer service, cutting response times dramatically (11 mins ➡️ under 2 mins). The whole organization is now AI-first.

It will be very interesting to see how public markets with evaluate this.

So this IPO isn't just Klarna's moment - it's FinTech's tipping point.

FinTech is back 🚀



<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/1.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/1.jpg" 
           alt="Nyx" 
          />
</a>
  </div>
</div>

<hr>
<hr>

<h1> 🚀 Introducing BeeAI </h1>

🚀 Introducing BeeAI: an IBM Open Source platform designed to make working with AI Agents simpler, more flexible, and more powerful.

Yesterday in San Francisco, some of my favorite colleagues from the IBM Research AI Incubation team presented the project's evolution at the AI Developer Conference organized by deeplearning ai.

With BeeAI, whether you're building your own agents or leveraging existing ones, BeeAI helps you discover, run, and compose AI agents across any framework or language.

A few highlights the team is especially proud of:

𝟭/ 𝗜𝘁 𝗶𝘀 𝗙𝗿𝗮𝗺𝗲𝘄𝗼𝗿𝗸-𝗮𝗴𝗻𝗼𝘀𝘁𝗶𝗰: Connect AI agents seamlessly, regardless of their language or platform.

𝟮/ 𝗠𝗼𝗱𝘂𝗹𝗮𝗿 𝗱𝗲𝘀𝗶𝗴𝗻: Construct sophisticated multi-agent workflows using modular components.

𝟯/ 𝗕𝘂𝗶𝗹𝘁-𝗶𝗻 𝗱𝗶𝘀𝗰𝗼𝘃𝗲𝗿𝘆: Explore a growing catalog of AI agents with an intuitive search.

𝟰/ 𝗗𝗲𝘃𝗲𝗹𝗼𝗽𝗲𝗿 𝘀𝘂𝗽𝗽𝗼𝗿𝘁: First-class tools for Python and TypeScript agent developers via the BeeAI Framework.

And it's open source under the Apache 2.0 license.

If you're working with agents or considering it, check out this out:

- Website: https://beeai.dev/

- Documentation: https://docs.beeai.dev/introduction/welcome

- Agent Library: https://beeai.dev/agents

- Repo: https://github.com/i-am-bee/beeai



<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/2.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/2.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1>🚫OpenAI Calls for Ban on Chinese Models  </h1>

The AI race is taking a geopolitical turn as OpenAI proposes sweeping restrictions against Chinese AI labs in its submission to the Trump Administration's "AI Action Plan."

▪️OpenAI has labeled DeepSeek as "state-subsidized" and "state-controlled" despite unclear evidence

▪️The proposal specifically recommends banning "PRC-produced" models in all "Tier 1" countries

▪️OpenAI claims Chinese models pose security risks, privacy concerns, and IP theft threats

▪️They previously accused DeepSeek of "distilling" knowledge from OpenAI's models

What do you think: Is OpenAI's proposal a legitimate security measure or a competitive strategy disguised as a policy recommendation?



<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/3.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/3.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1> Litserve is the new kid on the ML deployment block </h1>

This is the best way to deploy your Machine Learning model.

(I am not exaggerating)

Litserve is the new kid on the ML deployment block.

Based on FastAPI, 𝐥𝐢𝐭𝐬𝐞𝐫𝐯𝐞 provides a great serving engine for any model.

✅ Open-source

✅ Easy to use

✅ 2x faster than using FastAPI by yourself

✅ Supports Batching and Streaming

✅ GPU Autoscaling

✅ Automatic Dockerization

... and so much more!

I am in love with it because it is so easy to use and does not make things more complicated than they already are.

The team behind the project is also very active and supportive.


🔗 Check it out: https://github.com/Lightning-AI/LitServe


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/4.jpg"
      target="_blank">
      <img src="/assets/img/news/AI news/4.jpg" 
           alt="ClaudeCode" 
           />
</a>

  </div>
</div>

<hr>
<hr>

<h1> Opensource alternative to Manus AI Agent is blowing up on GitHub 🤯  </h1>

While everyone's fighting for Manus AI Agent invites.

Meet OWL by CAMEL-AI.org, the framework that topped the opensource benchmark for general AI agents: 

1. Specialized Multi-Agent Collaboration

↳ AI user agents break down complex tasks

↳ Assistant agents create detailed execution strategies

↳ Tool agents interface with external services and APIs

2. Advanced Real-World Capabilities

↳ Autonomous research, coding, and web browsing

↳ Runs locally on your machine for privacy

↳ Automates complex workflows from research to execution

3. Flexible Integration Options

↳ Supports Claude Sonnet 3.7, GPT-4o, DeepSeek, Gemini, and Ollama

↳ Fast installation via conda or uv with Docker support

↳ Straightforward configuration with TOML files

The best part?

It ranks 1 on the GAIA Benchmark among opensource projects.

With a 58.18 average score.

And unlike its competitors charging $20-$200 monthly, 

OWL is completely free.

No restrictions.

No invites.

No paywalls.

Just powerful autonomous AI Agents at your fingertips.

I believe AI autonomy shouldn't be locked behind exclusive access.

Or expensive subscriptions.

Have you tried OWL or any other AI agent frameworks?

What's your experience been like?

Check it out at: https://www.camel-ai.org/

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/WUSodzEgaog?si=ODQHG1F_ed9kI3Pp" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


  </div>
</div>

<hr>
<hr>

<h1> Switch to LitApi! </h1>

If you're still using FastAPI to deploy Hugging Face LLMs/VLMs - switch to LitApi!

FastAPI is a great framework for implementing RESTful APIs. 

However, it wasn’t specifically designed to handle the complex requirements of serving ML models at scale. 

The team at Lightning AI is behind LitServe and LitApi to fill in that gap.

🔹 𝗟𝗶𝘁𝗔𝗣𝗜 builds on top of FastAPI, adapting for ML workloads, standardizes the core steps of serving a model.

🔹 𝗟𝗶𝘁𝗦𝗲𝗿𝘃𝗲𝗿 handles the infrastructure side of serving models.

🔸 Here's what you must know:

1. 𝗢𝗻𝗲-𝘁𝗶𝗺𝗲 𝗺𝗼𝗱𝗲𝗹 𝘀𝗲𝘁𝘂𝗽

In the 𝙨𝙚𝙩𝙪𝙥() method, we can load any model only once.

2. 𝗖𝘂𝘀𝘁𝗼𝗺𝗶𝘇𝗲 𝗣𝗿𝗲𝗱𝗶𝗰𝘁

In the 𝙥𝙧𝙚𝙙𝙞𝙘𝙩() method, we implement the inference on inputs logic.

3. 𝗖𝘂𝘀𝘁𝗼𝗺𝗶𝘇𝗲 𝗕𝗮𝘁𝗰𝗵𝗶𝗻𝗴 𝗟𝗼𝗴𝗶𝗰

You can specify a MAX_BATCH_SIZE and a BATCH_TIME_WINDOW and it'll automatically handle the dynamic batching of requests as they come in concurrently.

You can use ThreadPoolExecutor to parallelize the preprocessing steps in the 𝙗𝙖𝙩𝙘𝙝() method.

4. 𝗖𝘂𝘀𝘁𝗼𝗺𝗶𝘇𝗲 𝗨𝗻𝗯𝗮𝘁𝗰𝗵𝗶𝗻𝗴 𝗟𝗼𝗴𝗶𝗰

After inferencing on a batch, you'll handle the detach () of GPU tensors and post-process the raw logits in the 𝙪𝙣𝙗𝙖𝙩𝙘𝙝() method.

5. 𝗗𝗲𝗰𝗼𝗱𝗲 𝗿𝗲𝗾𝘂𝗲𝘀𝘁 𝗮𝗻𝗱 𝗲𝗻𝗰𝗼𝗱𝗲 𝗿𝗲𝘀𝗽𝗼𝗻𝘀𝗲

In the 𝙙𝙚𝙘𝙤𝙙𝙚_𝙧𝙚𝙦𝙪𝙚𝙨𝙩() - specify how the API should access the input value from the request.

In the 𝙚𝙣𝙘𝙤𝙙𝙚_𝙧𝙚𝙨𝙥𝙤𝙣𝙨𝙚() - specify how the API should return responses to the client.

Simple as that!

To scale this up for a production workload, you'll use LitServe's scale configuration parameters:

```
LitServer(

 lit_api: LitAPI,

 accelerator: str = "auto",

 devices: Union[str, int] = "auto",

 workers_per_device: int = 1,

 timeout: Union[float, bool] = 30,

 max_batch_size: int = 1,

 batch_timeout: float = 0.0,

 stream: bool = False,

)

```

📙 For a full tutorial, see this article: https://neuralbits.substack.com/p/a-complete-tutorial-on-litservelitapi

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/6.jpg"
      target="_blank">
      <img src="/assets/img/news/AI news/6.jpg" 
           alt="BirdSQL" 
           />
</a>

  </div>
</div>

<hr>
<hr>

<h1> Reasoning Models 2.0, combine Reasoning with Tool Use! </h1>

✨ START teaches LLMs to use tools, such as code interpreter to improve reasoning and problem-solving. Self-taught Reasoner with Tools (START) integrates tool usage with chain-of-thought reasoning by enabling tool calls, self-check, exploration, and self-debug while reasoning using a self-learning framework. 👀

Implementation

1 Collect math problems (AIME, MATH) and coding tasks (Codeforces, LiveCodeBench)

2 Create context-specific hints like "Maybe using Python here is a good idea"

3 Generate tool-assisted reasoning data (insert hints after conjunctions like "Wait" and before stop tokens)

4 Score trajectories, remove repetitive patterns, and create a seed dataset with successful tool-assisted reasoning examples.

5 Fine-tune model on seed dataset, then self self-Distill to generate more diverse reasoning trajectories

6 Fine-tune the base model using rejection sampling (RFT) on the extended dataset

Insights

💡 Improves math accuracy by +15% (AMC23: 95.0%) and coding by +38.6% on medium problems.

📈 Test-time scaling via sequential hints boosts AIME24 performance by 12%.

🐞 Code template modification reduces debug errors by 41% in training data.

💡 Adding tools (Python interpreter) improves performance more than adding more training data.

🧠 Large models already possess latent tool-using abilities that can be activated through hints.

🛠️ Two-phase training (Hint-RFT then RFT) allows the model to learn effective tool usage.

📍 Hint place selection is important. After conjunction Token and before stop token.

Paper: https://huggingface.co/papers/2503.04625

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/7.jpg"
      target="_blank">
      <img src="/assets/img/news/AI news/7.jpg" 
           alt="Selene" 
           />
</a>

  </div>
</div>
