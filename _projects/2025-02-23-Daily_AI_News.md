---
layout: page
title: Daily AI news
date: 2025-04-06
description: This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI
img: assets/img/news/logo_SAK_15.PNG

images:
  lightbox2: false
  photoswipe: false
  spotlight: false
  venobox: false
---

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/logo_SAK_15.PNG"
      target="_blank">
      <img src="/assets/img/news/logo_SAK_15.PNG" 
           alt="Comapny Logo" 
           />
</a>
    
  </div>
</div>

<h1> 6th April 2025 </h1>

<hr>
<hr>

<h1> ğŸ‰ After months of hard work and collaboration, CAMEL-AI.org just release its new project LoongğŸ‰.  </h1>

The core concept of Loong is based on a simple assumption: an LLM equipped with a code interpreter and human-built libraries or tools can solve problems with significantly higher reliability compared to models that rely solely on natural language chain-of-thought reasoning. The performance gap between the two can be leveraged to generate synthetic data and for reinforcement learning. This is intuitive as wellâ€”many non-computer science fields (such as physics, economics, and computational biology) rely on code to solve practical problems in their daily research.

It is believed that the verifiability of RL rewards is one of the most important trends in RL for agents!

Project LoongğŸ‰ is officially released! Everyone is welcome to help build environments for agents!

Here is the <a href="https://github.com/camel-ai/loong"> project link </a> â€” please give them a star 


Friends interested in co-building can join their <a href="https://www.camel-ai.org/launchweek-environments"> initiative </a>


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/1.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/1.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1> â˜„ï¸Breaking News: Dartmouthâ€™s AI Therabot Reduces Depression Symptoms by 51% </h1>

First-ever clinical trial of Therabot, Dartmouth's AI-powered therapy chatbot, delivers remarkable outcomes.

Key highlights:

1ï¸âƒ£Depression symptoms reduced by 51%, anxiety by 31%, and eating disorder concerns by 19%â€”on par with traditional therapy.

2ï¸âƒ£Participants reported forming "therapeutic alliances" with Therabot, describing it as comparable to working with a human therapist.

3ï¸âƒ£Therabot offers 24/7 real-time support, filling critical gaps for those without access to mental health professionals.

Could AI therapy redefine the future of mental health care?

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/2.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/2.jpg" 
           alt="Nyx" 
          />
</a>
  </div>
</div>


<hr>
<hr>

<h1>  Gemma 3 Updates! </h1>

New QAT Google DeepMind Gemma 3 checkpoints with similar performance while using 3x less memory! ğŸ¤¯ 

Quantization-Aware Training (QAT) simulates low-precision operations during training to allow loss-less quantization afterwards for smaller, faster models while maintaining accuracy. We applied QAT on ~5,000 steps using probabilities from the non-quantized checkpoint as targets. ğŸ¯ 

Official QAT checkpoints for all Gemma 3 sizes are now available on Hugging Face, Kaggle and directly runnable with Ollama or llama.cpp ğŸ¤— 

<a href="https://huggingface.co/collections/google/gemma-3-qat-67ee61ccacbf2be4195c265b"> HF checkpoint </a>

Ollama command, remove the ():
``` 
ollama run hf(.)co/google/gemma-3-4b-it-qat-q4_0-gguf
```

One last thing, All Gemma 3 sizes (1B, 4B, 12B, 27B) now available AI Studio and via API to test.


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/3.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/3.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1>  Announcement from Fireworks AI </h1>

We just built something fun with Hugging Faceâ€™s new toolâ€” An AI crossword puzzle ğŸ§© 

This puzzle was created using DeepSiteâ€”an open-source, AI coding platform powered by DeepSeek AI V3.1 and hosted on Hugging Face Spaces.

With just a few instructions, it can generate:

â†’ Single-file HTML apps

â†’ Interactive tools

â†’ Even 3D games

No frameworks. No fancy prompt engineering!

And hereâ€™s the best part:

â†’ Itâ€™s completely free and open-source.

â†’ You can run it locally or deploy it in Docker.

Plus, Fireworks AI is one of the inference providers, making everything run smoothly.

Now, it's your turn to build something cool on <a href="https://huggingface.co/spaces/enzostvs/deepsite"> DeepSite </a>

ğŸ§© Start building here


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/4.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/4.jpg" 
           alt="Nyx" 
          />
</a>


  </div>
</div>

<hr>
<hr>

<h1>  China did it again! ByteDance just dropped an AI bombshell ğŸ˜³ </h1>

Meet DreamActor-M1, a next-gen AI model that brings full-body, expressive human animation to a whole new level.

Picture this:

- Snap ONE still photo of anyone.

- Pair it with ANY short video.

- Instantly transform it into a hyper-realistic, fully expressive animation.

Yes, the future arrived early.

Why DreamActor-M1 is huge:

â†’ Unmatched realism. Subtle smiles, tiny frowns - all are now captured perfectly with AI.

â†’ Creative Revolution. Filmmakers, creators, gamers - this means incredible animations for everyone without million-dollar budgets.

â†’ Social Media Magic. Turn selfies into videos in seconds. TikTok & Instagram are about to get even wilder.

But hereâ€™s the scary truth: with great power comes great risk.

â†³ Fake political speeches.

â†³ Misleading viral content.

â†³ Identity theft at scale.

This means we need an urgent ethics debate, and we need guidelines, fast.

DreamActor-M1 isn't just tech - itâ€™s a wake-up call.

Post Credit: Linas Beliunas


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
   <a href="/assets/img/news/AI news/5.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/5.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1> ğŸŒ³ğŸŒ³ Compose Anything is out ğŸŒ³ğŸŒ³  </h1>

ğŸ‘‰Skywork AI unveils SkyReels-A2, a controllable video generation framework capable of assembling arbitrary visual elements (e.g., characters, objects, backgrounds) into synthesized videos based on textual prompts. Code, models, & evaluation benchmark releasedğŸ’™

ğ‡ğ¢ğ ğ¡ğ¥ğ¢ğ ğ¡ğ­ğ¬:

âœ…SkyReels-A2: novel elements-to-video (E2V)

âœ…Multiple inputs: characters, objects & background 

âœ…Meticulously curated text-reference-video triplets

âœ…HQ, editable & temporally consistent multi-visual-elements videos

ğŸ‘‰ <a href="https://arxiv.org/pdf/2504.02436"> Paper </a> 

ğŸ‘‰ <a href="https://skyworkai.github.io/skyreels-a2.github.io/"> Project </a>  

ğŸ‘‰ <a href="https://github.com/SkyworkAI/SkyReels-A2"> Repo </a>  

ğŸ¤— <a href="https://huggingface.co/Skywork/SkyReels-A2"> Models </a>  

 
<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/6.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/6.jpg" 
           alt="Nyx" 
          />
</a>


  </div>
</div>

<hr>
<hr>

<h1> New announcement from You.com </h1>

Your research, your rules.

ARI, our deep research AI agent, now lets you:

ğŸŒ Customize your web sources â€“ include only the sites you trust and block the noise

ğŸ“‚ Add files â€“ get hyper-personalized insights by blending your knowledge with the web

Make ARI yours. No more generic answers. No more irrelevant sources.

Try it now on the Team plan 

<a href="https://you.com/"> Link </a>


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">

	<a href="/assets/img/news/AI news/7.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/7.jpg" 
           alt="Nyx" 
          />
</a>
  </div>
</div>
