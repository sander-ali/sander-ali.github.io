---
layout: page
title: Daily AI news
date: 2025-03-27
description: This page is dedicated to your daily AI news especially related to Agents, LLMs, and Agentic AI
img: assets/img/news/logo_SAK_15.PNG

images:
  lightbox2: false
  photoswipe: false
  spotlight: false
  venobox: false
---


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/logo_SAK_15.PNG"
      target="_blank">
      <img src="/assets/img/news/logo_SAK_15.PNG" 
           alt="Comapny Logo" 
           />
</a>

  </div>
</div>

<h1> 27th March 2025 </h1>

<h1> Breaking: Google DeepMind Drops Gemini 2.5 🔥  </h1>

Google DeepMind has just launched Gemini 2.5, its most advanced AI model yet, marking a significant leap in AI reasoning and coding capabilities. 

Key highlights of Gemini 2.5:

1️⃣Enhanced Reasoning: Gemini 2.5 Pro leads in benchmarks like math and science, showcasing strong logical analysis and decision-making.

2️⃣Advanced Coding: It excels in creating visually compelling web apps and agentic code applications, with notable improvements over previous models.

3️⃣Multimodal Capabilities: Gemini 2.5 supports a vast context window, handling complex data from various sources including text, audio, and video.

What do you think will be the most impactful use of Gemini 2.5 in the coming years?

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;">
      <iframe width="560" height="315" src="https://x.com/i/status/1904579419496386736"></iframe>
  </div>
</div>

<hr>
<hr>

<h1> Distil-whisper-large-v3.5 is released </h1>

Distil-whisper-large-v3.5 is released and now available on the Hub and featured on the Open ASR Leaderboard! This latest iteration represents a significant advancement in our speech recognition capabilities.​


Key Enhancements:

- Expanded Training Data: Leveraging over 98,000 hours of diverse audio, we've quadrupled our dataset to enhance model robustness and accuracy.​

- Advanced Training Techniques: Implemented a patient-teacher distillation approach with sophisticated data augmentation, leading to more reliable transcriptions.
​
- Improved Accuracy: Achieved a Word Error Rate (WER) of 7.21%, a notable improvement from the previous 7.52% in distil-large-v3.​

- Maintained Efficiency: Despite these enhancements, the model retains its high inference speed, ensuring swift and efficient performance.​

🔗 Links:

Open ASR Leaderboard: https://huggingface.co/spaces/hf-audio/open_asr_leaderboard

Model: https://huggingface.co/collections/distil-whisper/distil-large-v35-67e18241fb266177bed51674


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/2.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/2.jpg" 
           alt="Nyx" 
          />
</a>


  </div>
</div>

<hr>
<hr>

<h1> 🔥Breaking: Perplexity Introduces Answer Modes </h1>

Perplexity is transforming the search experience with innovative answer modes tailored for travel, shopping, and more!

Key Highlights:

🔸Enhanced Verticals: Answer modes now available for travel, shopping, places, images, videos, and jobs.

🔸Native Hotel Bookings: Partnering with TripAdvisor and Selfbook to offer seamless hotel bookings directly on Perplexity.

🔸Precision Search: Moving towards a tab-free experience for super precise results.

🔸Mobile Expansion: Mobile version launching soon.

This shift isn't just about answering questions; it's about creating a seamless, intuitive experience that changes the game.

What features do you think will be the next big leap for AI-powered search platforms?


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/3.jpg"

      target="_blank">
      <video width="320" height="240" autoplay>
  <source src="/assets/img/news/AI news/perplexity.mp4" type="video/mp4"> </video>
</a>

  </div>
</div>

<hr>
<hr>

<h1>  𝗗𝗼 𝘆𝗼𝘂 𝗸𝗻𝗼𝘄 𝗵𝗼𝘄 𝗺𝘂𝗰𝗵 𝗶𝘁 𝗰𝗼𝘀𝘁𝘀 𝘁𝗼 𝘁𝗿𝗮𝗶𝗻 𝗹𝗮𝗿𝗴𝗲 𝗹𝗮𝗻𝗴𝘂𝗮𝗴𝗲 𝗺𝗼𝗱𝗲𝗹𝘀 (𝗟𝗟𝗠𝘀)? ⬇️  </h1>

AI training costs are exploding lately. The Stanford AI Index Report has just released some training numbers and they are 𝗖𝗥𝗔𝗭𝗬:

→ Original Transformer Model: $930 

→ GPT-3: $4.3M 

→ GPT-4: $78.4M
 
→ Gemini Ultra: $191.4M

Training LLMs from scratch costs millions and these numbers are expected to climb even higher with the development of new models. This is why primarily Big Tech companies and well-funded startups can afford to undertake such projects. But why is this the case? 

Here’s the explanation:

1️⃣ Data:

→ Curating TBs of data and extensive pre-processing are needed. This involves collecting, cleaning, and organizing data to ensure the model trains on high-quality information. This task is resource-intensive, requiring significant time and manpower.

2️⃣ AI Talent and Skills:

→ Developing LLMs requires top researchers, with compensation at companies like OpenAI rumored up to $10M. A team of machine learning, data science, and linguistic experts is essential. They design neural networks, manage training processes, and assess performance. The significant cost of hiring and retaining this skilled workforce is crucial.

3️⃣ AI Computing Power:

→ Training and developing LLMs is incredibly expensive due to the vast computational resources required, with models like GPT-4 needing thousands of GPUs running for months (!). This extensive use of GPUs, combined with the need for continuous fine-tuning and experimentation, significantly drives up both the hardware and operational costs.

What does this mean for business?

→ Take existing LLM models and enhance them with your enterprise data using techniques like RAG or fine-tuning. 

And yes IBM Granite could be a good starting point for that: https://www.ibm.com/granite

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/4.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/4.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>

<hr>
<hr>

<h1> Langfuse are happy to announce our native integration with atla </h1>

Langfuse are happy to announce our native integration with atla, which brings their evaluation model Selene 1 to Langfuse (YC W23)!

Users can now run model-based evaluations (LLM-as-a-judge) with Selene, a model trained specifically to evaluate AI responses. 

𝗪𝗵𝗮𝘁 𝗮𝗿𝗲 𝗟𝗟𝗠-𝗮𝘀-𝗮-𝗝𝘂𝗱𝗴𝗲 𝗲𝘃𝗮𝗹𝘂𝗮𝘁𝗶𝗼𝗻𝘀?

Automated LLM-as-a-Judge evaluations involve using one LLM to assess and score the outputs of another model. This approach is often used in eval workflows, enabling scoring of large numbers of LLM traces. Using specialized evaluation models for this can be an advantage as they often outperform state-of-the-art models on these tasks. 

Check out the Atla blog to learn how to set up the Evaluations in Langfuse.

🔗 Link to Atla blog: https://www.atla-ai.com/post/langfuse-native-integration 

🔗 Link to Langfuse Eval docs: https://langfuse.com/docs/scores/overview


<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <a href="/assets/img/news/AI news/5.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/5.jpg" 
           alt="Nyx" 
          />
</a>


  </div>
</div>

<hr>
<hr>

<h1> OpenAI Unveils Revolutionary Image Capabilities in ChatGPT </h1>

🚀Breaking News: OpenAI Unveils Revolutionary Image Capabilities in ChatGPT

Key updates:

1️⃣Incredible Technology: The quality of these AI-generated images is astounding, pushing the boundaries of what was thought possible with AI. 

2️⃣Creative Freedom: This feature empowers users with unprecedented creative control, allowing them to explore new ideas while ensuring responsible use. 

3️⃣Responsible Innovation: OpenAI is committed to balancing intellectual freedom with societal norms, ensuring that their tools align with the values of users and the broader community. 

What do you think will be the most impactful application of AI-generated images in your field?

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/hTNAYbopAaA?si=aIXuvgsXouxHkxSk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

  </div>
</div>

<hr>
<hr>

<h1> How good is Gemini 2.5 Pro long context really? </h1>

How good is Gemini 2.5 Pro long context really? Fiction.LiveBench, designed for deep story comprehension, shows it's the clear sota leader (25% lead)!

Fiction.LiveBench evaluates true narrative understanding, including tracking evolving relationships, interpreting subtext, and predicting outcomes based on subtle hints – rather than just information retrieval.

The author says “This is the first time a LLM is potentially usable for long context writing. I'm interested in testing larger token sizes with this now.”

👉 https://fiction.live/stories/Fiction-liveBench-Mar-25-2025/oQdzQvKHw8JyXbN87

<div style="display: flex; justify-content: center; align-items: center;">
  <div class="pswp-gallery pswp-gallery--single-column" id="gallery--news" style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
   <a href="/assets/img/news/AI news/7.jpg"

      target="_blank">
      <img src="/assets/img/news/AI news/7.jpg" 
           alt="Nyx" 
          />
</a>

  </div>
</div>
